{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import keras as keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense,BatchNormalization,Dropout,Flatten, Conv1D\n",
    "from keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras import regularizers,optimizers\n",
    "from keras.regularizers import l2\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "from keras.layers.core import Lambda\n",
    "from scipy.integrate import trapz\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.layers.core import Lambda\n",
    "from keras import backend as K    \n",
    "\n",
    "\n",
    "def mini_batches(InputSample,BatchSize):\n",
    "    Index = np.array(range(InputSample.shape[0]),dtype=int)\n",
    "    NumBatches = np.int(InputSample.shape[0]/BatchSize)\n",
    "    Removed = np.array([],dtype=int)\n",
    "\n",
    "    BatchInd =[]\n",
    "    for BatchLoop in range(NumBatches):\n",
    "        RemainIndex = np.delete(Index,Removed)\n",
    "        SampleInd = np.random.choice(RemainIndex,size=BatchSize,replace=False)\n",
    "        Removed = np.append(Removed,SampleInd,axis=0)\n",
    "\n",
    "        BatchInd.append(SampleInd)\n",
    "    RemainIndex = np.delete(Index,Removed)\n",
    "    BatchInd.append(RemainIndex)\n",
    "\n",
    "    return BatchInd,NumBatches\n",
    "    \n",
    "def Get_Feats_and_Targets(filename):\n",
    "    import numpy as np\n",
    "    \n",
    "    def line_to_Feats(line):\n",
    "        line = line.split(' ')\n",
    "        Feats = np.asarray(line[0:1024])\n",
    "        Target = np.zeros([3])\n",
    "        Target[int(line[1024])] = 1\n",
    "        return Feats,Target\n",
    "\n",
    "    f = open(filename, 'r')\n",
    "    lines = f.readlines()\n",
    "    Features = []\n",
    "    Targets = []\n",
    "    for i in range(len(lines)-1):\n",
    "        line = lines[i+1]\n",
    "        Feats,Tgts = line_to_Feats(line)\n",
    "        Features.append(Feats)\n",
    "        Targets.append(Tgts)\n",
    "        \n",
    "    return np.asarray(Features,dtype = 'float64'), np.asarray(Targets,dtype = 'int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FullInputs = scipy.io.loadmat('MNIST_TrainInputs.mat')\n",
    "FullInputs = FullInputs['images']\n",
    "\n",
    "FullTargets = scipy.io.loadmat('MNIST_TrainTargets.mat')\n",
    "FullTargets = FullTargets['targets']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Validation_Cutoff = 0.75\n",
    "\n",
    "Validation_Cutoff = np.int(Validation_Cutoff*FullInputs.shape[0])\n",
    "\n",
    "ValInputs = FullInputs[Validation_Cutoff:,:]\n",
    "ValTargets = FullTargets[Validation_Cutoff:,:]\n",
    "\n",
    "TrainInputs = FullInputs[0:Validation_Cutoff,:]\n",
    "TrainTargets = FullTargets[0:Validation_Cutoff,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dim = TrainInputs.shape[-1]\n",
    "NumSamples = TrainInputs.shape[0]\n",
    "Num_Targets = TrainTargets.shape[-1]\n",
    "\n",
    "index = np.linspace(0,NumSamples,NumSamples,endpoint=False,dtype=int)\n",
    "\n",
    "reg_coeff = 0.001\n",
    "\n",
    "def Gen_Model(reg_coeff):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100,activation='relu',input_shape =(data_dim,),kernel_regularizer=l2(reg_coeff)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(100,activation='relu',input_shape =(data_dim,),kernel_regularizer=l2(reg_coeff)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(100,activation='relu',input_shape =(data_dim,),kernel_regularizer=l2(reg_coeff)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(Num_Targets,activation = 'softmax',kernel_regularizer=l2(reg_coeff),input_shape =(data_dim,)))\n",
    "    optim = optimizers.adam(lr=0.0001)\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=optim,metrics=['categorical_accuracy'])\n",
    "    return model\n",
    "    \n",
    "D2THard_model = Gen_Model(reg_coeff)\n",
    "D2TEasy_model = Gen_Model(reg_coeff)\n",
    "BALDHard_model = Gen_Model(reg_coeff)\n",
    "BALDEasy_model = Gen_Model(reg_coeff)\n",
    "\n",
    "Uni_model = Gen_Model(reg_coeff)\n",
    "\n",
    "D2THard_model.set_weights(Uni_model.get_weights())\n",
    "D2TEasy_model.set_weights(Uni_model.get_weights())\n",
    "BALDHard_model.set_weights(Uni_model.get_weights())\n",
    "BALDEasy_model.set_weights(Uni_model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def acquisition_function_BALD(model,samples,Num_Targets,temperature=1,Target_Ratio = 5):\n",
    "    nb_MC_samples = 30\n",
    "    MC_output = K.function([model.layers[0].input, K.learning_phase()], [model.layers[-1].output])\n",
    "    MC_samples = np.zeros([nb_MC_samples,samples.shape[0],Num_Targets])\n",
    "    learning_phase = True \n",
    "    for i in range(nb_MC_samples):\n",
    "        MC_samples[i,:,:] = np.array([MC_output([samples, learning_phase])[0]])\n",
    "        \n",
    "    expected_entropy = - np.mean(np.sum(MC_samples * np.log(MC_samples + 1e-10), axis=-1), axis=0)  # [batch size]\n",
    "    expected_p = np.mean(MC_samples, axis=0)\n",
    "    entropy_expected_p = - np.sum(expected_p * np.log(expected_p + 1e-10), axis=-1)  # [batch size]\n",
    "    BALD_acq = entropy_expected_p - expected_entropy\n",
    "    \n",
    "    Exp_BALD = np.exp(BALD_acq/temperature)\n",
    "    Sampling_Prob = Exp_BALD/np.sum(Exp_BALD).astype(float)\n",
    "    \n",
    "    Max_Prob_Ratio = Sampling_Prob.max()/Sampling_Prob.min()\n",
    "    Target_Ratio = Target_Ratio\n",
    "    if Max_Prob_Ratio < Target_Ratio:\n",
    "        while Max_Prob_Ratio <Target_Ratio:\n",
    "            temperature = temperature*0.99\n",
    "            Exp_BALD = np.exp(BALD_acq/temperature)\n",
    "            StoreSampling_Prob = Sampling_Prob.copy()\n",
    "            Sampling_Prob = Exp_BALD/np.sum(Exp_BALD).astype(float)\n",
    "            Max_Prob_Ratio = Sampling_Prob.max()/Sampling_Prob.min()\n",
    "            if np.isnan(Max_Prob_Ratio):\n",
    "                Sampling_Prob = StoreSampling_Prob.copy()\n",
    "    else:\n",
    "        while Max_Prob_Ratio > Target_Ratio:\n",
    "            temperature = temperature*1.01\n",
    "            Exp_BALD = np.exp(BALD_acq/temperature)\n",
    "            StoreSampling_Prob = Sampling_Prob.copy()\n",
    "            Sampling_Prob = Exp_BALD/np.sum(Exp_BALD).astype(float)\n",
    "            Max_Prob_Ratio = Sampling_Prob.max()/Sampling_Prob.min()\n",
    "            if np.isnan(Max_Prob_Ratio):\n",
    "                Sampling_Prob = StoreSampling_Prob.copy()\n",
    "    return Sampling_Prob\n",
    "\n",
    "def acquisition_function_BALD_const_temp(model,samples,Num_Targets,temperature=1):\n",
    "    nb_MC_samples =30\n",
    "    MC_output = K.function([model.layers[0].input, K.learning_phase()], [model.layers[-1].output])\n",
    "    MC_samples = np.zeros([nb_MC_samples,samples.shape[0],Num_Targets])\n",
    "    learning_phase = True \n",
    "    for i in range(nb_MC_samples):\n",
    "        MC_samples[i,:,:] = np.array([MC_output([samples, learning_phase])[0]])\n",
    "        \n",
    "    expected_entropy = - np.mean(np.sum(MC_samples * np.log(MC_samples + 1e-10), axis=-1), axis=0)  # [batch size]\n",
    "    expected_p = np.mean(MC_samples, axis=0)\n",
    "    entropy_expected_p = - np.sum(expected_p * np.log(expected_p + 1e-10), axis=-1)  # [batch size]\n",
    "    BALD_acq = entropy_expected_p - expected_entropy\n",
    "    \n",
    "    Exp_BALD = np.exp(BALD_acq/temperature)\n",
    "    Sampling_Prob = Exp_BALD/np.sum(Exp_BALD).astype(float)\n",
    "    return Sampling_Prob\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def average_dist_to_threshold(model,samples,Num_Targets):\n",
    "    Output = model.predict(samples)\n",
    "    Output -= 1/float(Num_Targets)\n",
    "    Dist_to_Threshold = np.mean(np.abs(Output),1)\n",
    "    return Dist_to_Threshold\n",
    "\n",
    "def acquisition_function_dist_to_threshold(model,samples,Num_Targets,temperature=1,Target_Ratio=5):\n",
    "    Output = model.predict(samples)\n",
    "    Output -= 1/float(Num_Targets)\n",
    "    Dist_to_Threshold = np.sum(np.abs(Output),1)\n",
    "    Exp_Dist_to_Threshold = np.exp(Dist_to_Threshold/temperature)\n",
    "    Exp_Dist_to_Threshold *= 1\n",
    "#     Exp_Dist_to_Threshold = Dist_to_Threshold\n",
    "    Sampling_Prob = Exp_Dist_to_Threshold/np.sum(Exp_Dist_to_Threshold).astype(float)\n",
    "    Max_Prob_Ratio = Sampling_Prob.max()/Sampling_Prob.min()\n",
    "    Target_Ratio = Target_Ratio\n",
    "    if Max_Prob_Ratio < Target_Ratio:\n",
    "        while Max_Prob_Ratio <Target_Ratio:\n",
    "            temperature = temperature*0.99\n",
    "            Exp_Dist_to_Threshold = np.exp(Dist_to_Threshold/temperature)\n",
    "            StoreSampling_Prob = Sampling_Prob.copy()\n",
    "            Sampling_Prob = Exp_Dist_to_Threshold/np.sum(Exp_Dist_to_Threshold).astype(float)\n",
    "            Max_Prob_Ratio = Sampling_Prob.max()/Sampling_Prob.min()\n",
    "            if np.isnan(Max_Prob_Ratio):\n",
    "                Sampling_Prob = StoreSampling_Prob.copy()\n",
    "    else:\n",
    "        while Max_Prob_Ratio > Target_Ratio:\n",
    "            temperature = temperature*1.01\n",
    "            Exp_Dist_to_Threshold = np.exp(Dist_to_Threshold/temperature)\n",
    "            StoreSampling_Prob = Sampling_Prob.copy()\n",
    "            Sampling_Prob = Exp_Dist_to_Threshold/np.sum(Exp_Dist_to_Threshold).astype(float)\n",
    "            Max_Prob_Ratio = Sampling_Prob.max()/Sampling_Prob.min()\n",
    "            if np.isnan(Max_Prob_Ratio):\n",
    "                Sampling_Prob = StoreSampling_Prob.copy()\n",
    "    return Sampling_Prob\n",
    "\n",
    "def acquisition_function_dist_to_threshold_const_temp(model,samples,Num_Targets,temperature=1):\n",
    "    Output = model.predict(samples)\n",
    "    Output -= 1/float(Num_Targets)\n",
    "    Dist_to_Threshold = np.sum(np.abs(Output),1)\n",
    "    Exp_Dist_to_Threshold = np.exp(Dist_to_Threshold/temperature)\n",
    "    Sampling_Prob = Exp_Dist_to_Threshold/np.sum(Exp_Dist_to_Threshold).astype(float)\n",
    "    return Sampling_Prob\n",
    "\n",
    "def acquisition_function_entropy(model,samples,Num_Targets,temperature=1,Target_Ratio=5):\n",
    "    Output = model.predict(samples)\n",
    "    Entropy = -np.sum(Output * np.log(Output),1)\n",
    "    Exp_Entropy = np.exp(Entropy/temperature)\n",
    "    Sampling_Prob = Exp_Entropy/np.sum(Exp_Entropy).astype(float)\n",
    "    Max_Prob_Ratio = Sampling_Prob.max()/Sampling_Prob.min()\n",
    "    Target_Ratio = Target_Ratio\n",
    "    if Max_Prob_Ratio < Target_Ratio:\n",
    "        while Max_Prob_Ratio <Target_Ratio:\n",
    "            temperature = temperature*0.99\n",
    "            Exp_Entropy = np.exp(Entropy/temperature)\n",
    "            StoreSampling_Prob = Sampling_Prob.copy()\n",
    "            Sampling_Prob = Exp_Entropy/np.sum(Exp_Entropy).astype(float)\n",
    "            Max_Prob_Ratio = Sampling_Prob.max()/Sampling_Prob.min()\n",
    "            if np.isnan(Max_Prob_Ratio):\n",
    "                Sampling_Prob = StoreSampling_Prob.copy()\n",
    "    else:\n",
    "        while Max_Prob_Ratio > Target_Ratio:\n",
    "            temperature = temperature*1.01\n",
    "            Exp_Entropy = np.exp(Entropy/temperature)\n",
    "            StoreSampling_Prob = Sampling_Prob.copy()\n",
    "            Sampling_Prob = Exp_Entropy/np.sum(Exp_Entropy).astype(float)\n",
    "            Max_Prob_Ratio = Sampling_Prob.max()/Sampling_Prob.min()\n",
    "            if np.isnan(Max_Prob_Ratio):\n",
    "                Sampling_Prob = StoreSampling_Prob.copy()\n",
    "    return Sampling_Prob\n",
    "\n",
    "def Exp_ModelChange(Model,Inputs,Num_Targets):\n",
    "    ExpChange = np.zeros(Inputs.shape[0])\n",
    "    Model_Output = Model.predict(Inputs)\n",
    "    for TargetLoop in range(Num_Targets):\n",
    "        thisTarget = np.zeros([Inputs.shape[0],Num_Targets])\n",
    "        thisTarget[:,TargetLoop] = 1\n",
    "        ClassProb = Model_Output[:,TargetLoop]\n",
    "        Loss = np.mean(Model_Output - Model_Output*thisTarget + np.log(1+np.exp(-Model_Output)),1)\n",
    "        ExpChange += Loss*ClassProb\n",
    "    return ExpChange\n",
    "\n",
    "def acquisition_function_exp_model_change(model,samples,Num_Targets,temperature = 1,Target_Ratio = 5):\n",
    "    ExpectedChange = Exp_ModelChange(model,samples,Num_Targets)\n",
    "    ExpChange = np.exp(ExpectedChange/temperature)\n",
    "    Sampling_Prob = ExpChange/np.sum(ExpChange).astype(float)\n",
    "    Max_Prob_Ratio = Sampling_Prob.max()/Sampling_Prob.min()\n",
    "    if Max_Prob_Ratio < Target_Ratio:\n",
    "        while Max_Prob_Ratio <Target_Ratio:\n",
    "            temperature = temperature*0.99\n",
    "            ExpChange = np.exp(ExpectedChange/temperature)\n",
    "            Sampling_Prob = ExpChange/np.sum(ExpChange).astype(float)\n",
    "            Max_Prob_Ratio = Sampling_Prob.max()/Sampling_Prob.min()\n",
    "    else:\n",
    "        while Max_Prob_Ratio > Target_Ratio:\n",
    "            temperature = temperature*1.01\n",
    "            ExpChange = np.exp(ExpectedChange/temperature)\n",
    "            Sampling_Prob = ExpChange/np.sum(ExpChange).astype(float)\n",
    "            Max_Prob_Ratio = Sampling_Prob.max()/Sampling_Prob.min()\n",
    "    return Sampling_Prob\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ablate_network(model,ablation_perc):\n",
    "    weights = model.get_weights()\n",
    "    save_weights = list(weights)\n",
    "    NumLayers = len(weights)\n",
    "    total_numweights  = 0 \n",
    "    for i in range(NumLayers):\n",
    "        layer = weights[i]\n",
    "        total_numweights += len(layer.flatten())\n",
    "    num_ablations = np.int(ablation_perc*total_numweights)\n",
    "    weights = ablate_weights(weights,num_ablations)\n",
    "    model.set_weights(weights)\n",
    "        \n",
    "    return(model,save_weights)\n",
    "\n",
    "\n",
    "def ablation_curve(model,num_tests,max_perc,inputs,targets):\n",
    "    Perc_Space = np.linspace(0,max_perc,num_tests)\n",
    "    Performance = np.zeros(num_tests)\n",
    "    for i in range(num_tests):\n",
    "        model,save_weights = ablate_network(model,Perc_Space[i])\n",
    "        Perf = model.test_on_batch(inputs,targets)\n",
    "        Performance[i] = Perf[1]\n",
    "        model.set_weights(save_weights)\n",
    "        AUC = trapz(Performance,Perc_Space)\n",
    "        \n",
    "    return AUC,Performance\n",
    "    \n",
    "    \n",
    "def ablate_weights(weights,num_ablations):\n",
    "    NumLayers = len(weights)\n",
    "    LayerShape = []\n",
    "    LayerShape = []\n",
    "    LayerNodes = [0]\n",
    "    FlattenedNodes = np.empty([0])\n",
    "    for i in range(NumLayers):\n",
    "        LayerShape.append(weights[i].shape)\n",
    "        LayerNodes.append(len(weights[i].flatten()))\n",
    "        FlattenedNodes = np.append(FlattenedNodes,weights[i].flatten())\n",
    "        Index = np.linspace(0,len(FlattenedNodes)-1,num=len(FlattenedNodes),dtype = int)\n",
    "    RandChoice = np.random.choice(Index,size = num_ablations,replace=False)\n",
    "    FlattenedNodes[RandChoice] = 0\n",
    "    FirstInd = 0\n",
    "    for i in range(NumLayers):\n",
    "        FirstInd += LayerNodes[i]\n",
    "        SecondInd = FirstInd + LayerNodes[i+1]\n",
    "        Sample = FlattenedNodes[FirstInd:SecondInd]\n",
    "        Sample = Sample.reshape(LayerShape[i])\n",
    "        weights[i] = Sample\n",
    "        \n",
    "    return weights\n",
    "\n",
    "\n",
    "def acquisition_function_ablation(model,Inputs,Targets,Cluster_Size,temperature=1,Target_Ratio = 5):\n",
    "    BatchInd,NumBatches = mini_batches(Inputs,Cluster_Size)\n",
    "    AUC_Record = np.zeros([Inputs.shape[0]])\n",
    "    count= 0\n",
    "    for Batch in BatchInd:\n",
    "        if Batch.shape[0] != 0:\n",
    "            BatchInputs = Inputs[Batch,:]\n",
    "            BatchTargets = Targets[Batch,:]\n",
    "            SaveWeights = model.get_weights()\n",
    "            model.fit(BatchInputs,BatchTargets,batch_size=64,verbose=0)\n",
    "            AUC,_ = ablation_curve(model,10,1,Inputs,Targets)\n",
    "            AUC_Record[Batch] = AUC.copy()\n",
    "            model.set_weights(SaveWeights)\n",
    "            count +=1\n",
    "            \n",
    "    Exp_AUC = np.exp(AUC_Record/temperature)\n",
    "    Sampling_Prob = AUC_Record/AUC_Record.sum()\n",
    "    Max_Prob_Ratio = Sampling_Prob.max()/Sampling_Prob.min()\n",
    "    if Max_Prob_Ratio < Target_Ratio:\n",
    "        while Max_Prob_Ratio <Target_Ratio:\n",
    "            temperature = temperature*0.99\n",
    "            Exp_AUC = np.exp(AUC_Record/temperature)\n",
    "            Sampling_Prob = Exp_AUC/np.sum(Exp_AUC).astype(float)\n",
    "            Max_Prob_Ratio = Sampling_Prob.max()/Sampling_Prob.min()\n",
    "    else:\n",
    "        while Max_Prob_Ratio > Target_Ratio:\n",
    "            temperature = temperature*1.01\n",
    "            Exp_AUC = np.exp(AUC_Record/temperature)\n",
    "            Sampling_Prob = Exp_AUC/np.sum(Exp_AUC).astype(float)\n",
    "            Max_Prob_Ratio = Sampling_Prob.max()/Sampling_Prob.min()\n",
    "\n",
    "    return Sampling_Prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "count = 0 \n",
    "Num_Epochs = 100\n",
    "Num_BurnIn = 1\n",
    "Batch_Size = 50\n",
    "\n",
    "NumTasks = 3\n",
    "try:\n",
    "    SwitchPoint = np.int(Num_Epochs/NumTasks)\n",
    "    print(SwitchPoint)\n",
    "except:\n",
    "    SwitchPoint = 1\n",
    "Smoothing_Constant = 0\n",
    "\n",
    "Val_Error = np.zeros([Num_Epochs,4])\n",
    "Val_Acc = np.zeros([Num_Epochs,4])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "45000/45000 [==============================] - 4s 96us/step - loss: 1.5751 - categorical_accuracy: 0.5953 - val_loss: 0.7531 - val_categorical_accuracy: 0.8868\n",
      "Epoch 2/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.8683 - categorical_accuracy: 0.8316 - val_loss: 0.6131 - val_categorical_accuracy: 0.9107\n",
      "Epoch 3/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.7259 - categorical_accuracy: 0.8737 - val_loss: 0.5542 - val_categorical_accuracy: 0.9217\n",
      "Epoch 4/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.6531 - categorical_accuracy: 0.8929 - val_loss: 0.5120 - val_categorical_accuracy: 0.9319\n",
      "Epoch 5/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.5974 - categorical_accuracy: 0.9073 - val_loss: 0.4807 - val_categorical_accuracy: 0.9377\n",
      "Epoch 6/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.5588 - categorical_accuracy: 0.9167 - val_loss: 0.4553 - val_categorical_accuracy: 0.9423\n",
      "Epoch 7/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.5229 - categorical_accuracy: 0.9226 - val_loss: 0.4272 - val_categorical_accuracy: 0.9482\n",
      "Epoch 8/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.4939 - categorical_accuracy: 0.9282 - val_loss: 0.4145 - val_categorical_accuracy: 0.9488\n",
      "Epoch 9/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.4670 - categorical_accuracy: 0.9350 - val_loss: 0.3922 - val_categorical_accuracy: 0.9525\n",
      "Epoch 10/100\n",
      "45000/45000 [==============================] - 4s 84us/step - loss: 0.4470 - categorical_accuracy: 0.9373 - val_loss: 0.3752 - val_categorical_accuracy: 0.9558\n",
      "Epoch 11/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.4267 - categorical_accuracy: 0.9415 - val_loss: 0.3611 - val_categorical_accuracy: 0.9579\n",
      "Epoch 12/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.4133 - categorical_accuracy: 0.9426 - val_loss: 0.3499 - val_categorical_accuracy: 0.9595\n",
      "Epoch 13/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.3966 - categorical_accuracy: 0.9459 - val_loss: 0.3371 - val_categorical_accuracy: 0.9617\n",
      "Epoch 14/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.3830 - categorical_accuracy: 0.9488 - val_loss: 0.3302 - val_categorical_accuracy: 0.9615\n",
      "Epoch 15/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.3732 - categorical_accuracy: 0.9498 - val_loss: 0.3185 - val_categorical_accuracy: 0.9638\n",
      "Epoch 16/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.3572 - categorical_accuracy: 0.9536 - val_loss: 0.3122 - val_categorical_accuracy: 0.9633\n",
      "Epoch 17/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.3545 - categorical_accuracy: 0.9521 - val_loss: 0.3056 - val_categorical_accuracy: 0.9654\n",
      "Epoch 18/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.3456 - categorical_accuracy: 0.9533 - val_loss: 0.2997 - val_categorical_accuracy: 0.9652\n",
      "Epoch 19/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.3413 - categorical_accuracy: 0.9541 - val_loss: 0.2936 - val_categorical_accuracy: 0.9662\n",
      "Epoch 20/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.3300 - categorical_accuracy: 0.9568 - val_loss: 0.2887 - val_categorical_accuracy: 0.9665\n",
      "Epoch 21/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.3217 - categorical_accuracy: 0.9580 - val_loss: 0.2840 - val_categorical_accuracy: 0.9681\n",
      "Epoch 22/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.3193 - categorical_accuracy: 0.9575 - val_loss: 0.2783 - val_categorical_accuracy: 0.9685\n",
      "Epoch 23/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.3109 - categorical_accuracy: 0.9597 - val_loss: 0.2749 - val_categorical_accuracy: 0.9686\n",
      "Epoch 24/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.3081 - categorical_accuracy: 0.9599 - val_loss: 0.2728 - val_categorical_accuracy: 0.9685\n",
      "Epoch 25/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.3034 - categorical_accuracy: 0.9607 - val_loss: 0.2690 - val_categorical_accuracy: 0.9691\n",
      "Epoch 26/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2970 - categorical_accuracy: 0.9613 - val_loss: 0.2639 - val_categorical_accuracy: 0.9707\n",
      "Epoch 27/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2931 - categorical_accuracy: 0.9627 - val_loss: 0.2647 - val_categorical_accuracy: 0.9699\n",
      "Epoch 28/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2929 - categorical_accuracy: 0.9618 - val_loss: 0.2600 - val_categorical_accuracy: 0.9706\n",
      "Epoch 29/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2892 - categorical_accuracy: 0.9636 - val_loss: 0.2587 - val_categorical_accuracy: 0.9702\n",
      "Epoch 30/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2821 - categorical_accuracy: 0.9643 - val_loss: 0.2551 - val_categorical_accuracy: 0.9711\n",
      "Epoch 31/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2823 - categorical_accuracy: 0.9645 - val_loss: 0.2560 - val_categorical_accuracy: 0.9703\n",
      "Epoch 32/100\n",
      "45000/45000 [==============================] - 4s 82us/step - loss: 0.2788 - categorical_accuracy: 0.9649 - val_loss: 0.2537 - val_categorical_accuracy: 0.9713\n",
      "Epoch 33/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2788 - categorical_accuracy: 0.9654 - val_loss: 0.2526 - val_categorical_accuracy: 0.9715\n",
      "Epoch 34/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2752 - categorical_accuracy: 0.9657 - val_loss: 0.2495 - val_categorical_accuracy: 0.9721\n",
      "Epoch 35/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2701 - categorical_accuracy: 0.9670 - val_loss: 0.2469 - val_categorical_accuracy: 0.9718\n",
      "Epoch 36/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2693 - categorical_accuracy: 0.9670 - val_loss: 0.2461 - val_categorical_accuracy: 0.9725\n",
      "Epoch 37/100\n",
      "45000/45000 [==============================] - 4s 82us/step - loss: 0.2689 - categorical_accuracy: 0.9668 - val_loss: 0.2478 - val_categorical_accuracy: 0.9721\n",
      "Epoch 38/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2674 - categorical_accuracy: 0.9670 - val_loss: 0.2450 - val_categorical_accuracy: 0.9721\n",
      "Epoch 39/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2638 - categorical_accuracy: 0.9679 - val_loss: 0.2434 - val_categorical_accuracy: 0.9723\n",
      "Epoch 40/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2664 - categorical_accuracy: 0.9671 - val_loss: 0.2437 - val_categorical_accuracy: 0.9719\n",
      "Epoch 41/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2624 - categorical_accuracy: 0.9681 - val_loss: 0.2415 - val_categorical_accuracy: 0.9723\n",
      "Epoch 42/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2601 - categorical_accuracy: 0.9691 - val_loss: 0.2422 - val_categorical_accuracy: 0.9717\n",
      "Epoch 43/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2597 - categorical_accuracy: 0.9683 - val_loss: 0.2396 - val_categorical_accuracy: 0.9729\n",
      "Epoch 44/100\n",
      "45000/45000 [==============================] - 4s 82us/step - loss: 0.2584 - categorical_accuracy: 0.9690 - val_loss: 0.2401 - val_categorical_accuracy: 0.9721\n",
      "Epoch 45/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2577 - categorical_accuracy: 0.9692 - val_loss: 0.2377 - val_categorical_accuracy: 0.9729\n",
      "Epoch 46/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2578 - categorical_accuracy: 0.9694 - val_loss: 0.2372 - val_categorical_accuracy: 0.9723\n",
      "Epoch 47/100\n",
      "45000/45000 [==============================] - 4s 87us/step - loss: 0.2548 - categorical_accuracy: 0.9692 - val_loss: 0.2386 - val_categorical_accuracy: 0.9730\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2545 - categorical_accuracy: 0.9703 - val_loss: 0.2374 - val_categorical_accuracy: 0.9727\n",
      "Epoch 49/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2551 - categorical_accuracy: 0.9696 - val_loss: 0.2374 - val_categorical_accuracy: 0.9725\n",
      "Epoch 50/100\n",
      "45000/45000 [==============================] - 4s 84us/step - loss: 0.2548 - categorical_accuracy: 0.9694 - val_loss: 0.2368 - val_categorical_accuracy: 0.9723\n",
      "Epoch 51/100\n",
      "45000/45000 [==============================] - 4s 87us/step - loss: 0.2529 - categorical_accuracy: 0.9700 - val_loss: 0.2358 - val_categorical_accuracy: 0.9727\n",
      "Epoch 52/100\n",
      "45000/45000 [==============================] - 4s 84us/step - loss: 0.2541 - categorical_accuracy: 0.9697 - val_loss: 0.2336 - val_categorical_accuracy: 0.9737\n",
      "Epoch 53/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2536 - categorical_accuracy: 0.9697 - val_loss: 0.2344 - val_categorical_accuracy: 0.9731\n",
      "Epoch 54/100\n",
      "45000/45000 [==============================] - 4s 84us/step - loss: 0.2510 - categorical_accuracy: 0.9707 - val_loss: 0.2346 - val_categorical_accuracy: 0.9733\n",
      "Epoch 55/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2491 - categorical_accuracy: 0.9703 - val_loss: 0.2326 - val_categorical_accuracy: 0.9741\n",
      "Epoch 56/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2485 - categorical_accuracy: 0.9708 - val_loss: 0.2332 - val_categorical_accuracy: 0.9735\n",
      "Epoch 57/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2485 - categorical_accuracy: 0.9708 - val_loss: 0.2338 - val_categorical_accuracy: 0.9731\n",
      "Epoch 58/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2465 - categorical_accuracy: 0.9718 - val_loss: 0.2332 - val_categorical_accuracy: 0.9730\n",
      "Epoch 59/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2475 - categorical_accuracy: 0.9714 - val_loss: 0.2345 - val_categorical_accuracy: 0.9727\n",
      "Epoch 60/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2461 - categorical_accuracy: 0.9712 - val_loss: 0.2327 - val_categorical_accuracy: 0.9731\n",
      "Epoch 61/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2483 - categorical_accuracy: 0.9705 - val_loss: 0.2303 - val_categorical_accuracy: 0.9747\n",
      "Epoch 62/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2460 - categorical_accuracy: 0.9714 - val_loss: 0.2315 - val_categorical_accuracy: 0.9741\n",
      "Epoch 63/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2451 - categorical_accuracy: 0.9716 - val_loss: 0.2335 - val_categorical_accuracy: 0.9727\n",
      "Epoch 64/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2456 - categorical_accuracy: 0.9710 - val_loss: 0.2308 - val_categorical_accuracy: 0.9744\n",
      "Epoch 65/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2448 - categorical_accuracy: 0.9720 - val_loss: 0.2321 - val_categorical_accuracy: 0.9728\n",
      "Epoch 66/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2430 - categorical_accuracy: 0.9721 - val_loss: 0.2291 - val_categorical_accuracy: 0.9752\n",
      "Epoch 67/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2439 - categorical_accuracy: 0.9710 - val_loss: 0.2304 - val_categorical_accuracy: 0.9739\n",
      "Epoch 68/100\n",
      "45000/45000 [==============================] - 4s 84us/step - loss: 0.2442 - categorical_accuracy: 0.9723 - val_loss: 0.2299 - val_categorical_accuracy: 0.9741\n",
      "Epoch 69/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2436 - categorical_accuracy: 0.9722 - val_loss: 0.2292 - val_categorical_accuracy: 0.9733\n",
      "Epoch 70/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2409 - categorical_accuracy: 0.9726 - val_loss: 0.2298 - val_categorical_accuracy: 0.9754\n",
      "Epoch 71/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2405 - categorical_accuracy: 0.9731 - val_loss: 0.2291 - val_categorical_accuracy: 0.9739\n",
      "Epoch 72/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2427 - categorical_accuracy: 0.9720 - val_loss: 0.2307 - val_categorical_accuracy: 0.9737\n",
      "Epoch 73/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2414 - categorical_accuracy: 0.9719 - val_loss: 0.2300 - val_categorical_accuracy: 0.9750\n",
      "Epoch 74/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2419 - categorical_accuracy: 0.9724 - val_loss: 0.2295 - val_categorical_accuracy: 0.9739\n",
      "Epoch 75/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2414 - categorical_accuracy: 0.9722 - val_loss: 0.2305 - val_categorical_accuracy: 0.9736\n",
      "Epoch 76/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2414 - categorical_accuracy: 0.9718 - val_loss: 0.2279 - val_categorical_accuracy: 0.9740\n",
      "Epoch 77/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2400 - categorical_accuracy: 0.9717 - val_loss: 0.2295 - val_categorical_accuracy: 0.9737\n",
      "Epoch 78/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2398 - categorical_accuracy: 0.9732 - val_loss: 0.2296 - val_categorical_accuracy: 0.9741\n",
      "Epoch 79/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2400 - categorical_accuracy: 0.9720 - val_loss: 0.2286 - val_categorical_accuracy: 0.9742\n",
      "Epoch 80/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2396 - categorical_accuracy: 0.9725 - val_loss: 0.2277 - val_categorical_accuracy: 0.9756\n",
      "Epoch 81/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2393 - categorical_accuracy: 0.9719 - val_loss: 0.2282 - val_categorical_accuracy: 0.9748\n",
      "Epoch 82/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2370 - categorical_accuracy: 0.9738 - val_loss: 0.2288 - val_categorical_accuracy: 0.9741\n",
      "Epoch 83/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2396 - categorical_accuracy: 0.9730 - val_loss: 0.2279 - val_categorical_accuracy: 0.9746\n",
      "Epoch 84/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2382 - categorical_accuracy: 0.9732 - val_loss: 0.2290 - val_categorical_accuracy: 0.9744\n",
      "Epoch 85/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2400 - categorical_accuracy: 0.9729 - val_loss: 0.2266 - val_categorical_accuracy: 0.9755\n",
      "Epoch 86/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2386 - categorical_accuracy: 0.9726 - val_loss: 0.2280 - val_categorical_accuracy: 0.9752\n",
      "Epoch 87/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2384 - categorical_accuracy: 0.9723 - val_loss: 0.2293 - val_categorical_accuracy: 0.9731\n",
      "Epoch 88/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2368 - categorical_accuracy: 0.9738 - val_loss: 0.2276 - val_categorical_accuracy: 0.9748\n",
      "Epoch 89/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2374 - categorical_accuracy: 0.9732 - val_loss: 0.2286 - val_categorical_accuracy: 0.9746\n",
      "Epoch 90/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2367 - categorical_accuracy: 0.9738 - val_loss: 0.2274 - val_categorical_accuracy: 0.9745\n",
      "Epoch 91/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2367 - categorical_accuracy: 0.9729 - val_loss: 0.2273 - val_categorical_accuracy: 0.9747\n",
      "Epoch 92/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2361 - categorical_accuracy: 0.9733 - val_loss: 0.2267 - val_categorical_accuracy: 0.9745\n",
      "Epoch 93/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2380 - categorical_accuracy: 0.9731 - val_loss: 0.2278 - val_categorical_accuracy: 0.9743\n",
      "Epoch 94/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2331 - categorical_accuracy: 0.9746 - val_loss: 0.2264 - val_categorical_accuracy: 0.9743\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2367 - categorical_accuracy: 0.9730 - val_loss: 0.2266 - val_categorical_accuracy: 0.9743\n",
      "Epoch 96/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2349 - categorical_accuracy: 0.9733 - val_loss: 0.2251 - val_categorical_accuracy: 0.9753\n",
      "Epoch 97/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2354 - categorical_accuracy: 0.9733 - val_loss: 0.2266 - val_categorical_accuracy: 0.9747\n",
      "Epoch 98/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2334 - categorical_accuracy: 0.9742 - val_loss: 0.2262 - val_categorical_accuracy: 0.9744\n",
      "Epoch 99/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2337 - categorical_accuracy: 0.9745 - val_loss: 0.2267 - val_categorical_accuracy: 0.9743\n",
      "Epoch 100/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2343 - categorical_accuracy: 0.9734 - val_loss: 0.2257 - val_categorical_accuracy: 0.9745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x455b06a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Uni_model.fit(TrainInputs,TrainTargets,batch_size = Batch_Size,epochs=Num_Epochs,verbose=1,validation_data=[ValInputs,ValTargets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dist_to_Threshold = acquisition_function_dist_to_threshold(Uni_model,TrainInputs,Num_Targets,1,10)\n",
    "BALD = acquisition_function_BALD(Uni_model,TrainInputs,Num_Targets,1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#'Easiest' First\n",
    "Easy_Dist_to_Threshold_ArgSort = np.flipud(Dist_to_Threshold.argsort())\n",
    "Hard_Dist_to_Threshold_ArgSort = Dist_to_Threshold.argsort()\n",
    "# Low_BALD_ArgSort = BALD.argsort()\n",
    "# High_BALD_ArgSort = np.flipud(BALD.argsort())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11250\n",
      "Epoch 1/100\n",
      "11250/11250 [==============================] - 1s 102us/step - loss: 2.5849 - categorical_accuracy: 0.1859\n",
      "Epoch 2/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 2.2494 - categorical_accuracy: 0.3251\n",
      "Epoch 3/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 1.9768 - categorical_accuracy: 0.4097\n",
      "Epoch 4/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 1.7958 - categorical_accuracy: 0.4686\n",
      "Epoch 5/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 1.6660 - categorical_accuracy: 0.5156\n",
      "Epoch 6/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 1.5880 - categorical_accuracy: 0.5463\n",
      "Epoch 7/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 1.5228 - categorical_accuracy: 0.5647\n",
      "Epoch 8/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 1.4530 - categorical_accuracy: 0.5952\n",
      "Epoch 9/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 1.3955 - categorical_accuracy: 0.6182\n",
      "Epoch 10/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 1.3579 - categorical_accuracy: 0.6323\n",
      "Epoch 11/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 1.3123 - categorical_accuracy: 0.6498\n",
      "Epoch 12/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 1.2795 - categorical_accuracy: 0.6619\n",
      "Epoch 13/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 1.2346 - categorical_accuracy: 0.6716\n",
      "Epoch 14/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 1.2103 - categorical_accuracy: 0.6899\n",
      "Epoch 15/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 1.1724 - categorical_accuracy: 0.7025\n",
      "Epoch 16/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 1.1468 - categorical_accuracy: 0.7136\n",
      "Epoch 17/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 1.1203 - categorical_accuracy: 0.7164\n",
      "Epoch 18/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 1.1025 - categorical_accuracy: 0.7271\n",
      "Epoch 19/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 1.0700 - categorical_accuracy: 0.7379\n",
      "Epoch 20/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 1.0534 - categorical_accuracy: 0.7372\n",
      "Epoch 21/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 1.0290 - categorical_accuracy: 0.7492\n",
      "Epoch 22/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 1.0077 - categorical_accuracy: 0.7659\n",
      "Epoch 23/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.9843 - categorical_accuracy: 0.7696\n",
      "Epoch 24/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.9776 - categorical_accuracy: 0.7695\n",
      "Epoch 25/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.9540 - categorical_accuracy: 0.7820\n",
      "Epoch 26/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.9415 - categorical_accuracy: 0.7859\n",
      "Epoch 27/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.9234 - categorical_accuracy: 0.7881\n",
      "Epoch 28/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.9079 - categorical_accuracy: 0.7996\n",
      "Epoch 29/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.8976 - categorical_accuracy: 0.8009\n",
      "Epoch 30/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.8820 - categorical_accuracy: 0.8030\n",
      "Epoch 31/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.8778 - categorical_accuracy: 0.8071\n",
      "Epoch 32/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.8662 - categorical_accuracy: 0.8083\n",
      "Epoch 33/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.8427 - categorical_accuracy: 0.8220\n",
      "Epoch 34/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.8460 - categorical_accuracy: 0.8149\n",
      "Epoch 35/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.8237 - categorical_accuracy: 0.8270\n",
      "Epoch 36/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.8078 - categorical_accuracy: 0.8282\n",
      "Epoch 37/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.8089 - categorical_accuracy: 0.8301\n",
      "Epoch 38/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.7915 - categorical_accuracy: 0.8347\n",
      "Epoch 39/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.7873 - categorical_accuracy: 0.8347\n",
      "Epoch 40/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.7759 - categorical_accuracy: 0.8428\n",
      "Epoch 41/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.7692 - categorical_accuracy: 0.8420\n",
      "Epoch 42/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.7569 - categorical_accuracy: 0.8466\n",
      "Epoch 43/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.7466 - categorical_accuracy: 0.8484\n",
      "Epoch 44/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.7363 - categorical_accuracy: 0.8524\n",
      "Epoch 45/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.7330 - categorical_accuracy: 0.8534\n",
      "Epoch 46/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.7217 - categorical_accuracy: 0.8593\n",
      "Epoch 47/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.7188 - categorical_accuracy: 0.8628\n",
      "Epoch 48/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.7146 - categorical_accuracy: 0.8569\n",
      "Epoch 49/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.7090 - categorical_accuracy: 0.8614\n",
      "Epoch 50/100\n",
      "11250/11250 [==============================] - 1s 62us/step - loss: 0.7001 - categorical_accuracy: 0.8638\n",
      "Epoch 51/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.6905 - categorical_accuracy: 0.8691\n",
      "Epoch 52/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.6811 - categorical_accuracy: 0.8679\n",
      "Epoch 53/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.6784 - categorical_accuracy: 0.8671\n",
      "Epoch 54/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.6713 - categorical_accuracy: 0.8697\n",
      "Epoch 55/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.6727 - categorical_accuracy: 0.8672\n",
      "Epoch 56/100\n",
      "11250/11250 [==============================] - 1s 60us/step - loss: 0.6668 - categorical_accuracy: 0.8743\n",
      "Epoch 57/100\n",
      "11250/11250 [==============================] - 1s 62us/step - loss: 0.6573 - categorical_accuracy: 0.8745\n",
      "Epoch 58/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.6479 - categorical_accuracy: 0.8778\n",
      "Epoch 59/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.6426 - categorical_accuracy: 0.8818\n",
      "Epoch 60/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.6368 - categorical_accuracy: 0.8838\n",
      "Epoch 61/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.6367 - categorical_accuracy: 0.8802\n",
      "Epoch 62/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.6313 - categorical_accuracy: 0.8846\n",
      "Epoch 63/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.6178 - categorical_accuracy: 0.8884\n",
      "Epoch 64/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.6141 - categorical_accuracy: 0.8924\n",
      "Epoch 65/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.6202 - categorical_accuracy: 0.8880\n",
      "Epoch 66/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.6081 - categorical_accuracy: 0.8908\n",
      "Epoch 67/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.6047 - categorical_accuracy: 0.8920\n",
      "Epoch 68/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.5961 - categorical_accuracy: 0.8956\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.5955 - categorical_accuracy: 0.8973\n",
      "Epoch 70/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.5909 - categorical_accuracy: 0.8935\n",
      "Epoch 71/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.5847 - categorical_accuracy: 0.8999\n",
      "Epoch 72/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.5900 - categorical_accuracy: 0.8976\n",
      "Epoch 73/100\n",
      "11250/11250 [==============================] - 1s 62us/step - loss: 0.5824 - categorical_accuracy: 0.8965\n",
      "Epoch 74/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.5774 - categorical_accuracy: 0.9021\n",
      "Epoch 75/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.5751 - categorical_accuracy: 0.8991\n",
      "Epoch 76/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.5763 - categorical_accuracy: 0.8949\n",
      "Epoch 77/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.5637 - categorical_accuracy: 0.9035\n",
      "Epoch 78/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.5610 - categorical_accuracy: 0.9046\n",
      "Epoch 79/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.5579 - categorical_accuracy: 0.9054\n",
      "Epoch 80/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.5595 - categorical_accuracy: 0.9044\n",
      "Epoch 81/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.5607 - categorical_accuracy: 0.9054\n",
      "Epoch 82/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.5548 - categorical_accuracy: 0.9043\n",
      "Epoch 83/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.5453 - categorical_accuracy: 0.9076\n",
      "Epoch 84/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.5534 - categorical_accuracy: 0.9072\n",
      "Epoch 85/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.5458 - categorical_accuracy: 0.9110\n",
      "Epoch 86/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.5405 - categorical_accuracy: 0.9100\n",
      "Epoch 87/100\n",
      "11250/11250 [==============================] - 1s 62us/step - loss: 0.5364 - categorical_accuracy: 0.9072\n",
      "Epoch 88/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.5278 - categorical_accuracy: 0.9121\n",
      "Epoch 89/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.5323 - categorical_accuracy: 0.9122\n",
      "Epoch 90/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.5283 - categorical_accuracy: 0.9150\n",
      "Epoch 91/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.5311 - categorical_accuracy: 0.9118\n",
      "Epoch 92/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.5216 - categorical_accuracy: 0.9151\n",
      "Epoch 93/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.5208 - categorical_accuracy: 0.9141\n",
      "Epoch 94/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.5189 - categorical_accuracy: 0.9176\n",
      "Epoch 95/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.5141 - categorical_accuracy: 0.9180\n",
      "Epoch 96/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.5161 - categorical_accuracy: 0.9192\n",
      "Epoch 97/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.5206 - categorical_accuracy: 0.9164\n",
      "Epoch 98/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.5164 - categorical_accuracy: 0.9173\n",
      "Epoch 99/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.5022 - categorical_accuracy: 0.9213\n",
      "Epoch 100/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.5005 - categorical_accuracy: 0.9243\n",
      "Epoch 1/100\n",
      "11250/11250 [==============================] - 1s 102us/step - loss: 1.9371 - categorical_accuracy: 0.5153\n",
      "Epoch 2/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.8640 - categorical_accuracy: 0.8728\n",
      "Epoch 3/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.5976 - categorical_accuracy: 0.9338\n",
      "Epoch 4/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.4882 - categorical_accuracy: 0.9567\n",
      "Epoch 5/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.4319 - categorical_accuracy: 0.9704\n",
      "Epoch 6/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.3998 - categorical_accuracy: 0.9757\n",
      "Epoch 7/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.3752 - categorical_accuracy: 0.9810\n",
      "Epoch 8/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.3535 - categorical_accuracy: 0.9845\n",
      "Epoch 9/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.3349 - categorical_accuracy: 0.9888\n",
      "Epoch 10/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.3217 - categorical_accuracy: 0.9898\n",
      "Epoch 11/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.3130 - categorical_accuracy: 0.9890\n",
      "Epoch 12/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.2964 - categorical_accuracy: 0.9928\n",
      "Epoch 13/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.2909 - categorical_accuracy: 0.9924\n",
      "Epoch 14/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.2802 - categorical_accuracy: 0.9939\n",
      "Epoch 15/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.2694 - categorical_accuracy: 0.9950\n",
      "Epoch 16/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.2606 - categorical_accuracy: 0.9948\n",
      "Epoch 17/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.2538 - categorical_accuracy: 0.9952\n",
      "Epoch 18/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.2439 - categorical_accuracy: 0.9956\n",
      "Epoch 19/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.2368 - categorical_accuracy: 0.9959\n",
      "Epoch 20/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.2292 - categorical_accuracy: 0.9960\n",
      "Epoch 21/100\n",
      "11250/11250 [==============================] - 1s 62us/step - loss: 0.2211 - categorical_accuracy: 0.9968\n",
      "Epoch 22/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.2145 - categorical_accuracy: 0.9966\n",
      "Epoch 23/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.2072 - categorical_accuracy: 0.9969\n",
      "Epoch 24/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.1994 - categorical_accuracy: 0.9972\n",
      "Epoch 25/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.1922 - categorical_accuracy: 0.9978\n",
      "Epoch 26/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.1859 - categorical_accuracy: 0.9978\n",
      "Epoch 27/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.1808 - categorical_accuracy: 0.9964\n",
      "Epoch 28/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.1758 - categorical_accuracy: 0.9969\n",
      "Epoch 29/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.1690 - categorical_accuracy: 0.9973\n",
      "Epoch 30/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.1661 - categorical_accuracy: 0.9972\n",
      "Epoch 31/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.1602 - categorical_accuracy: 0.9970\n",
      "Epoch 32/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.1562 - categorical_accuracy: 0.9981\n",
      "Epoch 33/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.1498 - categorical_accuracy: 0.9980\n",
      "Epoch 34/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.1467 - categorical_accuracy: 0.9977\n",
      "Epoch 35/100\n",
      "11250/11250 [==============================] - 1s 62us/step - loss: 0.1419 - categorical_accuracy: 0.9980\n",
      "Epoch 36/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.1392 - categorical_accuracy: 0.9972\n",
      "Epoch 37/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.1354 - categorical_accuracy: 0.9977\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.1317 - categorical_accuracy: 0.9982\n",
      "Epoch 39/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.1284 - categorical_accuracy: 0.9978\n",
      "Epoch 40/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.1249 - categorical_accuracy: 0.9983\n",
      "Epoch 41/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.1229 - categorical_accuracy: 0.9980\n",
      "Epoch 42/100\n",
      "11250/11250 [==============================] - 1s 62us/step - loss: 0.1190 - categorical_accuracy: 0.9981\n",
      "Epoch 43/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.1168 - categorical_accuracy: 0.9980\n",
      "Epoch 44/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.1150 - categorical_accuracy: 0.9988\n",
      "Epoch 45/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.1130 - categorical_accuracy: 0.9981\n",
      "Epoch 46/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.1106 - categorical_accuracy: 0.9983\n",
      "Epoch 47/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.1093 - categorical_accuracy: 0.9982\n",
      "Epoch 48/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.1089 - categorical_accuracy: 0.9982\n",
      "Epoch 49/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.1048 - categorical_accuracy: 0.9984\n",
      "Epoch 50/100\n",
      "11250/11250 [==============================] - 1s 62us/step - loss: 0.1029 - categorical_accuracy: 0.9985\n",
      "Epoch 51/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.1017 - categorical_accuracy: 0.9984\n",
      "Epoch 52/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.1002 - categorical_accuracy: 0.9983\n",
      "Epoch 53/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0984 - categorical_accuracy: 0.9991\n",
      "Epoch 54/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0980 - categorical_accuracy: 0.9983\n",
      "Epoch 55/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0965 - categorical_accuracy: 0.9988\n",
      "Epoch 56/100\n",
      "11250/11250 [==============================] - 1s 62us/step - loss: 0.0958 - categorical_accuracy: 0.9987\n",
      "Epoch 57/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0943 - categorical_accuracy: 0.9987\n",
      "Epoch 58/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0929 - categorical_accuracy: 0.9990\n",
      "Epoch 59/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0915 - categorical_accuracy: 0.9990\n",
      "Epoch 60/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0931 - categorical_accuracy: 0.9975\n",
      "Epoch 61/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0906 - categorical_accuracy: 0.9987\n",
      "Epoch 62/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0908 - categorical_accuracy: 0.9984\n",
      "Epoch 63/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0904 - categorical_accuracy: 0.9979\n",
      "Epoch 64/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0890 - categorical_accuracy: 0.9986\n",
      "Epoch 65/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0878 - categorical_accuracy: 0.9983\n",
      "Epoch 66/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0869 - categorical_accuracy: 0.9988\n",
      "Epoch 67/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0867 - categorical_accuracy: 0.9986\n",
      "Epoch 68/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0860 - categorical_accuracy: 0.9990\n",
      "Epoch 69/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0870 - categorical_accuracy: 0.9982\n",
      "Epoch 70/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0865 - categorical_accuracy: 0.9985\n",
      "Epoch 71/100\n",
      "11250/11250 [==============================] - 1s 62us/step - loss: 0.0849 - categorical_accuracy: 0.9988\n",
      "Epoch 72/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0857 - categorical_accuracy: 0.9987\n",
      "Epoch 73/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0838 - categorical_accuracy: 0.9990\n",
      "Epoch 74/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0839 - categorical_accuracy: 0.9980\n",
      "Epoch 75/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0833 - categorical_accuracy: 0.9987\n",
      "Epoch 76/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0832 - categorical_accuracy: 0.9991\n",
      "Epoch 77/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0831 - categorical_accuracy: 0.9986\n",
      "Epoch 78/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0815 - categorical_accuracy: 0.9990\n",
      "Epoch 79/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0816 - categorical_accuracy: 0.9988\n",
      "Epoch 80/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0807 - categorical_accuracy: 0.9990\n",
      "Epoch 81/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0817 - categorical_accuracy: 0.9984\n",
      "Epoch 82/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0815 - categorical_accuracy: 0.9985\n",
      "Epoch 83/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0804 - categorical_accuracy: 0.9989\n",
      "Epoch 84/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0800 - categorical_accuracy: 0.9988\n",
      "Epoch 85/100\n",
      "11250/11250 [==============================] - 1s 62us/step - loss: 0.0808 - categorical_accuracy: 0.9983\n",
      "Epoch 86/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0803 - categorical_accuracy: 0.9988\n",
      "Epoch 87/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0797 - categorical_accuracy: 0.9990\n",
      "Epoch 88/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0804 - categorical_accuracy: 0.9985\n",
      "Epoch 89/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0795 - categorical_accuracy: 0.9989\n",
      "Epoch 90/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0788 - categorical_accuracy: 0.9989\n",
      "Epoch 91/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0794 - categorical_accuracy: 0.9987\n",
      "Epoch 92/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0790 - categorical_accuracy: 0.9988\n",
      "Epoch 93/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0784 - categorical_accuracy: 0.9988\n",
      "Epoch 94/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0790 - categorical_accuracy: 0.9988\n",
      "Epoch 95/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0776 - categorical_accuracy: 0.9991\n",
      "Epoch 96/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0773 - categorical_accuracy: 0.9988\n",
      "Epoch 97/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0779 - categorical_accuracy: 0.9991\n",
      "Epoch 98/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0783 - categorical_accuracy: 0.9988\n",
      "Epoch 99/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0781 - categorical_accuracy: 0.9989\n",
      "Epoch 100/100\n",
      "11250/11250 [==============================] - 1s 61us/step - loss: 0.0784 - categorical_accuracy: 0.9988\n",
      "Epoch 1/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.4112 - categorical_accuracy: 0.9536\n",
      "Epoch 2/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3987 - categorical_accuracy: 0.9539\n",
      "Epoch 3/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.4009 - categorical_accuracy: 0.9531\n",
      "Epoch 4/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3989 - categorical_accuracy: 0.9532\n",
      "Epoch 5/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3898 - categorical_accuracy: 0.9550\n",
      "Epoch 6/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3946 - categorical_accuracy: 0.9521\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3888 - categorical_accuracy: 0.9524\n",
      "Epoch 8/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3861 - categorical_accuracy: 0.9517\n",
      "Epoch 9/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3828 - categorical_accuracy: 0.9531\n",
      "Epoch 10/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3836 - categorical_accuracy: 0.9522\n",
      "Epoch 11/50\n",
      "22500/22500 [==============================] - 1s 62us/step - loss: 0.3763 - categorical_accuracy: 0.9554\n",
      "Epoch 12/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3756 - categorical_accuracy: 0.9550\n",
      "Epoch 13/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3780 - categorical_accuracy: 0.9527\n",
      "Epoch 14/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3714 - categorical_accuracy: 0.9571\n",
      "Epoch 15/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3718 - categorical_accuracy: 0.9558\n",
      "Epoch 16/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3680 - categorical_accuracy: 0.9567\n",
      "Epoch 17/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3641 - categorical_accuracy: 0.9558\n",
      "Epoch 18/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3639 - categorical_accuracy: 0.9565\n",
      "Epoch 19/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3619 - categorical_accuracy: 0.9553\n",
      "Epoch 20/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3623 - categorical_accuracy: 0.9556\n",
      "Epoch 21/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3611 - categorical_accuracy: 0.9560\n",
      "Epoch 22/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3595 - categorical_accuracy: 0.9544\n",
      "Epoch 23/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3582 - categorical_accuracy: 0.9571\n",
      "Epoch 24/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3549 - categorical_accuracy: 0.9569\n",
      "Epoch 25/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3564 - categorical_accuracy: 0.9544\n",
      "Epoch 26/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3530 - categorical_accuracy: 0.9578\n",
      "Epoch 27/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3561 - categorical_accuracy: 0.9558\n",
      "Epoch 28/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3514 - categorical_accuracy: 0.9572\n",
      "Epoch 29/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3473 - categorical_accuracy: 0.9582\n",
      "Epoch 30/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3435 - categorical_accuracy: 0.9587\n",
      "Epoch 31/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3459 - categorical_accuracy: 0.9575\n",
      "Epoch 32/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3485 - categorical_accuracy: 0.9564\n",
      "Epoch 33/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3488 - categorical_accuracy: 0.9557\n",
      "Epoch 34/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3473 - categorical_accuracy: 0.9568\n",
      "Epoch 35/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3413 - categorical_accuracy: 0.9581\n",
      "Epoch 36/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3445 - categorical_accuracy: 0.9579\n",
      "Epoch 37/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3412 - categorical_accuracy: 0.9567\n",
      "Epoch 38/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3394 - categorical_accuracy: 0.9592\n",
      "Epoch 39/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3335 - categorical_accuracy: 0.9602\n",
      "Epoch 40/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3352 - categorical_accuracy: 0.9591\n",
      "Epoch 41/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3350 - categorical_accuracy: 0.9579\n",
      "Epoch 42/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3351 - categorical_accuracy: 0.9596\n",
      "Epoch 43/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3329 - categorical_accuracy: 0.9591\n",
      "Epoch 44/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3310 - categorical_accuracy: 0.9609\n",
      "Epoch 45/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3295 - categorical_accuracy: 0.9614\n",
      "Epoch 46/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3302 - categorical_accuracy: 0.9599\n",
      "Epoch 47/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3291 - categorical_accuracy: 0.9601\n",
      "Epoch 48/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3294 - categorical_accuracy: 0.9597\n",
      "Epoch 49/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3279 - categorical_accuracy: 0.9612\n",
      "Epoch 50/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.3256 - categorical_accuracy: 0.9613\n",
      "Epoch 1/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.1117 - categorical_accuracy: 0.9906\n",
      "Epoch 2/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.1025 - categorical_accuracy: 0.9943\n",
      "Epoch 3/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.1007 - categorical_accuracy: 0.9952\n",
      "Epoch 4/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0991 - categorical_accuracy: 0.9961\n",
      "Epoch 5/50\n",
      "22500/22500 [==============================] - 1s 62us/step - loss: 0.0992 - categorical_accuracy: 0.9958\n",
      "Epoch 6/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0980 - categorical_accuracy: 0.9963\n",
      "Epoch 7/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0973 - categorical_accuracy: 0.9966\n",
      "Epoch 8/50\n",
      "22500/22500 [==============================] - 1s 62us/step - loss: 0.0959 - categorical_accuracy: 0.9972\n",
      "Epoch 9/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0968 - categorical_accuracy: 0.9971\n",
      "Epoch 10/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0959 - categorical_accuracy: 0.9970\n",
      "Epoch 11/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0962 - categorical_accuracy: 0.9968\n",
      "Epoch 12/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0944 - categorical_accuracy: 0.9974\n",
      "Epoch 13/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0949 - categorical_accuracy: 0.9972\n",
      "Epoch 14/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0942 - categorical_accuracy: 0.9975\n",
      "Epoch 15/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0939 - categorical_accuracy: 0.9980 0s - loss: 0.0934 - categori\n",
      "Epoch 16/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0929 - categorical_accuracy: 0.9980\n",
      "Epoch 17/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0939 - categorical_accuracy: 0.9974\n",
      "Epoch 18/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0938 - categorical_accuracy: 0.9976\n",
      "Epoch 19/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0929 - categorical_accuracy: 0.9976\n",
      "Epoch 20/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0934 - categorical_accuracy: 0.9974\n",
      "Epoch 21/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0933 - categorical_accuracy: 0.9974\n",
      "Epoch 22/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0937 - categorical_accuracy: 0.9972\n",
      "Epoch 23/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0923 - categorical_accuracy: 0.9976\n",
      "Epoch 24/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0927 - categorical_accuracy: 0.9976\n",
      "Epoch 25/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0931 - categorical_accuracy: 0.9977\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0918 - categorical_accuracy: 0.9982\n",
      "Epoch 27/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0924 - categorical_accuracy: 0.9977\n",
      "Epoch 28/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0921 - categorical_accuracy: 0.9980\n",
      "Epoch 29/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0918 - categorical_accuracy: 0.9981\n",
      "Epoch 30/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0912 - categorical_accuracy: 0.9981\n",
      "Epoch 31/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0910 - categorical_accuracy: 0.9980\n",
      "Epoch 32/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0913 - categorical_accuracy: 0.9977\n",
      "Epoch 33/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0913 - categorical_accuracy: 0.9980\n",
      "Epoch 34/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0911 - categorical_accuracy: 0.9980\n",
      "Epoch 35/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0909 - categorical_accuracy: 0.9980\n",
      "Epoch 36/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0921 - categorical_accuracy: 0.9976\n",
      "Epoch 37/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0915 - categorical_accuracy: 0.9976\n",
      "Epoch 38/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0919 - categorical_accuracy: 0.9977\n",
      "Epoch 39/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0913 - categorical_accuracy: 0.9976\n",
      "Epoch 40/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0916 - categorical_accuracy: 0.9976\n",
      "Epoch 41/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0903 - categorical_accuracy: 0.9982\n",
      "Epoch 42/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0910 - categorical_accuracy: 0.9979\n",
      "Epoch 43/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0906 - categorical_accuracy: 0.9980\n",
      "Epoch 44/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0906 - categorical_accuracy: 0.9980\n",
      "Epoch 45/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0900 - categorical_accuracy: 0.9980\n",
      "Epoch 46/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0896 - categorical_accuracy: 0.9982\n",
      "Epoch 47/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0916 - categorical_accuracy: 0.9973\n",
      "Epoch 48/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0899 - categorical_accuracy: 0.9983\n",
      "Epoch 49/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0900 - categorical_accuracy: 0.9983\n",
      "Epoch 50/50\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.0899 - categorical_accuracy: 0.9979\n",
      "Epoch 1/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.2891 - categorical_accuracy: 0.9729\n",
      "Epoch 2/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.2884 - categorical_accuracy: 0.9708\n",
      "Epoch 3/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.2859 - categorical_accuracy: 0.9719\n",
      "Epoch 4/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.2852 - categorical_accuracy: 0.9711\n",
      "Epoch 5/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.2824 - categorical_accuracy: 0.9712\n",
      "Epoch 6/33\n",
      "33750/33750 [==============================] - 2s 62us/step - loss: 0.2834 - categorical_accuracy: 0.9707\n",
      "Epoch 7/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.2858 - categorical_accuracy: 0.9687\n",
      "Epoch 8/33\n",
      "33750/33750 [==============================] - 2s 62us/step - loss: 0.2818 - categorical_accuracy: 0.9706\n",
      "Epoch 9/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.2800 - categorical_accuracy: 0.9705\n",
      "Epoch 10/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.2776 - categorical_accuracy: 0.9716\n",
      "Epoch 11/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.2792 - categorical_accuracy: 0.9703\n",
      "Epoch 12/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.2805 - categorical_accuracy: 0.9687\n",
      "Epoch 13/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.2754 - categorical_accuracy: 0.9720\n",
      "Epoch 14/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.2750 - categorical_accuracy: 0.9708\n",
      "Epoch 15/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.2801 - categorical_accuracy: 0.9695\n",
      "Epoch 16/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.2764 - categorical_accuracy: 0.9707\n",
      "Epoch 17/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.2792 - categorical_accuracy: 0.9696\n",
      "Epoch 18/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.2757 - categorical_accuracy: 0.9709\n",
      "Epoch 19/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.2739 - categorical_accuracy: 0.9704\n",
      "Epoch 20/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.2716 - categorical_accuracy: 0.9723\n",
      "Epoch 21/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.2746 - categorical_accuracy: 0.9692\n",
      "Epoch 22/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.2719 - categorical_accuracy: 0.9704\n",
      "Epoch 23/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.2722 - categorical_accuracy: 0.9706\n",
      "Epoch 24/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.2723 - categorical_accuracy: 0.9703\n",
      "Epoch 25/33\n",
      "33750/33750 [==============================] - 2s 62us/step - loss: 0.2697 - categorical_accuracy: 0.9724\n",
      "Epoch 26/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.2743 - categorical_accuracy: 0.9691\n",
      "Epoch 27/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.2709 - categorical_accuracy: 0.9700\n",
      "Epoch 28/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.2668 - categorical_accuracy: 0.9715\n",
      "Epoch 29/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.2696 - categorical_accuracy: 0.9704\n",
      "Epoch 30/33\n",
      "33750/33750 [==============================] - 2s 62us/step - loss: 0.2686 - categorical_accuracy: 0.9713\n",
      "Epoch 31/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.2690 - categorical_accuracy: 0.9720\n",
      "Epoch 32/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.2707 - categorical_accuracy: 0.9701\n",
      "Epoch 33/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.2646 - categorical_accuracy: 0.9725\n",
      "Epoch 1/33\n",
      "33750/33750 [==============================] - 2s 62us/step - loss: 0.1294 - categorical_accuracy: 0.9882\n",
      "Epoch 2/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.1224 - categorical_accuracy: 0.9913\n",
      "Epoch 3/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.1202 - categorical_accuracy: 0.9919\n",
      "Epoch 4/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.1178 - categorical_accuracy: 0.9935\n",
      "Epoch 5/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.1166 - categorical_accuracy: 0.9948\n",
      "Epoch 6/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.1169 - categorical_accuracy: 0.9940\n",
      "Epoch 7/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.1161 - categorical_accuracy: 0.9946\n",
      "Epoch 8/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.1155 - categorical_accuracy: 0.9948\n",
      "Epoch 9/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.1164 - categorical_accuracy: 0.9946\n",
      "Epoch 10/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.1151 - categorical_accuracy: 0.9948\n",
      "Epoch 11/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.1154 - categorical_accuracy: 0.9950\n",
      "Epoch 12/33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.1150 - categorical_accuracy: 0.9957\n",
      "Epoch 13/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.1134 - categorical_accuracy: 0.9955\n",
      "Epoch 14/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.1136 - categorical_accuracy: 0.9959\n",
      "Epoch 15/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.1138 - categorical_accuracy: 0.9953\n",
      "Epoch 16/33\n",
      "33750/33750 [==============================] - 2s 62us/step - loss: 0.1134 - categorical_accuracy: 0.9958\n",
      "Epoch 17/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.1125 - categorical_accuracy: 0.9961\n",
      "Epoch 18/33\n",
      "33750/33750 [==============================] - 2s 62us/step - loss: 0.1126 - categorical_accuracy: 0.9962\n",
      "Epoch 19/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.1135 - categorical_accuracy: 0.9956\n",
      "Epoch 20/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.1128 - categorical_accuracy: 0.9960\n",
      "Epoch 21/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.1118 - categorical_accuracy: 0.9961\n",
      "Epoch 22/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.1135 - categorical_accuracy: 0.9955\n",
      "Epoch 23/33\n",
      "33750/33750 [==============================] - 2s 62us/step - loss: 0.1131 - categorical_accuracy: 0.9961\n",
      "Epoch 24/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.1122 - categorical_accuracy: 0.9961\n",
      "Epoch 25/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.1126 - categorical_accuracy: 0.9960\n",
      "Epoch 26/33\n",
      "33750/33750 [==============================] - 2s 62us/step - loss: 0.1119 - categorical_accuracy: 0.9961\n",
      "Epoch 27/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.1122 - categorical_accuracy: 0.9961\n",
      "Epoch 28/33\n",
      "33750/33750 [==============================] - 2s 62us/step - loss: 0.1125 - categorical_accuracy: 0.9961\n",
      "Epoch 29/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.1115 - categorical_accuracy: 0.9958\n",
      "Epoch 30/33\n",
      "33750/33750 [==============================] - 2s 62us/step - loss: 0.1118 - categorical_accuracy: 0.9961\n",
      "Epoch 31/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.1115 - categorical_accuracy: 0.9966\n",
      "Epoch 32/33\n",
      "33750/33750 [==============================] - 2s 61us/step - loss: 0.1104 - categorical_accuracy: 0.9964\n",
      "Epoch 33/33\n",
      "33750/33750 [==============================] - 2s 62us/step - loss: 0.1112 - categorical_accuracy: 0.9963\n",
      "Epoch 1/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2423 - categorical_accuracy: 0.9780\n",
      "Epoch 2/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2417 - categorical_accuracy: 0.9774\n",
      "Epoch 3/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2414 - categorical_accuracy: 0.9768\n",
      "Epoch 4/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2422 - categorical_accuracy: 0.9762\n",
      "Epoch 5/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2390 - categorical_accuracy: 0.9769\n",
      "Epoch 6/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2406 - categorical_accuracy: 0.9764\n",
      "Epoch 7/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2400 - categorical_accuracy: 0.9755\n",
      "Epoch 8/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2406 - categorical_accuracy: 0.9758\n",
      "Epoch 9/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2396 - categorical_accuracy: 0.9758\n",
      "Epoch 10/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2384 - categorical_accuracy: 0.9759\n",
      "Epoch 11/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2389 - categorical_accuracy: 0.9756\n",
      "Epoch 12/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2391 - categorical_accuracy: 0.9749\n",
      "Epoch 13/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2384 - categorical_accuracy: 0.9758\n",
      "Epoch 14/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2385 - categorical_accuracy: 0.9751\n",
      "Epoch 15/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2370 - categorical_accuracy: 0.9761\n",
      "Epoch 16/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2356 - categorical_accuracy: 0.9755\n",
      "Epoch 17/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2373 - categorical_accuracy: 0.9744\n",
      "Epoch 18/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2358 - categorical_accuracy: 0.9749\n",
      "Epoch 19/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2367 - categorical_accuracy: 0.9745\n",
      "Epoch 20/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2359 - categorical_accuracy: 0.9758\n",
      "Epoch 21/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2349 - categorical_accuracy: 0.9755\n",
      "Epoch 22/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2362 - categorical_accuracy: 0.9753\n",
      "Epoch 23/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2346 - categorical_accuracy: 0.9765\n",
      "Epoch 24/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2368 - categorical_accuracy: 0.9739\n",
      "Epoch 25/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2345 - categorical_accuracy: 0.9743\n",
      "Epoch 1/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.3299 - categorical_accuracy: 0.9326\n",
      "Epoch 2/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.3036 - categorical_accuracy: 0.9420\n",
      "Epoch 3/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2910 - categorical_accuracy: 0.9446\n",
      "Epoch 4/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2817 - categorical_accuracy: 0.9483\n",
      "Epoch 5/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2803 - categorical_accuracy: 0.9500\n",
      "Epoch 6/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2764 - categorical_accuracy: 0.9524\n",
      "Epoch 7/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2718 - categorical_accuracy: 0.9535\n",
      "Epoch 8/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2653 - categorical_accuracy: 0.9568\n",
      "Epoch 9/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2620 - categorical_accuracy: 0.9584\n",
      "Epoch 10/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2617 - categorical_accuracy: 0.9585\n",
      "Epoch 11/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2600 - categorical_accuracy: 0.9586\n",
      "Epoch 12/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2587 - categorical_accuracy: 0.9601\n",
      "Epoch 13/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2578 - categorical_accuracy: 0.9607\n",
      "Epoch 14/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2535 - categorical_accuracy: 0.9617\n",
      "Epoch 15/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2521 - categorical_accuracy: 0.9621\n",
      "Epoch 16/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2518 - categorical_accuracy: 0.9623\n",
      "Epoch 17/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2509 - categorical_accuracy: 0.9634\n",
      "Epoch 18/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2500 - categorical_accuracy: 0.9636\n",
      "Epoch 19/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2471 - categorical_accuracy: 0.9647\n",
      "Epoch 20/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2474 - categorical_accuracy: 0.9653\n",
      "Epoch 21/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2463 - categorical_accuracy: 0.9654\n",
      "Epoch 22/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2454 - categorical_accuracy: 0.9659\n",
      "Epoch 23/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2451 - categorical_accuracy: 0.9664\n",
      "Epoch 24/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2477 - categorical_accuracy: 0.9660\n",
      "Epoch 25/25\n",
      "45000/45000 [==============================] - 3s 61us/step - loss: 0.2409 - categorical_accuracy: 0.9682\n"
     ]
    }
   ],
   "source": [
    "NumTasks = 4\n",
    "TaskSplitPoints = np.int(np.ceil(NumSamples/NumTasks))\n",
    "print(TaskSplitPoints)\n",
    "for i in range(NumTasks):\n",
    "    Num_Epochs_Task = Num_Epochs*(1/(i+1))\n",
    "\n",
    "    TaskInd = Hard_Dist_to_Threshold_ArgSort[0:np.min([(i+1)*TaskSplitPoints,NumSamples])]\n",
    "    D2THard_model.fit(TrainInputs[TaskInd,:],TrainTargets[TaskInd],batch_size=Batch_Size,epochs = np.int(Num_Epochs_Task))\n",
    "    \n",
    "    TaskInd = Easy_Dist_to_Threshold_ArgSort[0:np.min([(i+1)*TaskSplitPoints,NumSamples])]\n",
    "    D2TEasy_model.fit(TrainInputs[TaskInd,:],TrainTargets[TaskInd],batch_size=Batch_Size,epochs = np.int(Num_Epochs_Task))\n",
    "    \n",
    "#     TaskInd = Low_BALD_ArgSort[0:np.min([(i+1)*TaskSplitPoints,NumSamples])]\n",
    "#     BALDEasy_model.fit(TrainInputs[TaskInd,:],TrainTargets[TaskInd],batch_size=Batch_Size,epochs = np.int(Num_Epochs_Task))\n",
    "    \n",
    "#     TaskInd = High_BALD_ArgSort[0:np.min([(i+1)*TaskSplitPoints,NumSamples])]\n",
    "#     BALDHard_model.fit(TrainInputs[TaskInd,:],TrainTargets[TaskInd],batch_size=Batch_Size,epochs = np.int(Num_Epochs_Task))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TestInputs = scipy.io.loadmat('MNIST_TestInputs.mat')\n",
    "TestInputs = TestInputs['test_images']\n",
    "\n",
    "TestTargets = scipy.io.loadmat('MNIST_TestTargets.mat')\n",
    "TestTargets = TestTargets['test_targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TestError = np.zeros([5,2])\n",
    "TestError[0,:] = D2THard_model.test_on_batch(TestInputs,TestTargets)\n",
    "TestError[1,:] = D2TEasy_model.test_on_batch(TestInputs,TestTargets)\n",
    "TestError[2,:] = BALDHard_model.test_on_batch(TestInputs,TestTargets)\n",
    "TestError[3,:] = BALDEasy_model.test_on_batch(TestInputs,TestTargets)\n",
    "TestError[4,:] = Uni_model.test_on_batch(TestInputs,TestTargets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21901147, 0.97869998],\n",
       "       [0.21968949, 0.97180003],\n",
       "       [2.70712543, 0.0962    ],\n",
       "       [2.70712543, 0.0962    ],\n",
       "       [0.21657991, 0.97750002]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
