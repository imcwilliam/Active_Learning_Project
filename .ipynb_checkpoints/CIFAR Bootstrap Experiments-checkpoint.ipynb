{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CIFAR_Bootstrap_Exp(Num_Tasks,Num_Epochs):\n",
    "    %matplotlib notebook\n",
    "    import cntk\n",
    "    cntk.device.try_set_default_device(cntk.device.gpu(0))\n",
    "    import os\n",
    "    os.environ['KERAS_BACKEND'] = 'cntk'\n",
    "    import keras as keras\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import LSTM, Dense,BatchNormalization,Dropout,Flatten, Conv1D, Conv2D, MaxPool2D\n",
    "    from keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "    from keras.metrics import categorical_accuracy\n",
    "    from keras import regularizers,optimizers\n",
    "    from keras.regularizers import l2\n",
    "    import numpy as np\n",
    "    import scipy.io\n",
    "    import matplotlib.pyplot as plt\n",
    "    import gzip\n",
    "    from keras.layers.core import Lambda\n",
    "    from scipy.integrate import trapz\n",
    "    import seaborn as sns\n",
    "\n",
    "    from keras.layers.core import Lambda\n",
    "    from keras import backend as K    \n",
    "    \n",
    "    print(K.cntk_backend.dev.use_default_device())\n",
    "\n",
    "    def mini_batches(InputSample,BatchSize):\n",
    "        Index = np.array(range(InputSample.shape[0]),dtype=int)\n",
    "        NumBatches = np.int(InputSample.shape[0]/BatchSize)\n",
    "        Removed = np.array([],dtype=int)\n",
    "\n",
    "        BatchInd =[]\n",
    "        for BatchLoop in range(NumBatches):\n",
    "            RemainIndex = np.delete(Index,Removed)\n",
    "            SampleInd = np.random.choice(RemainIndex,size=BatchSize,replace=False)\n",
    "            Removed = np.append(Removed,SampleInd,axis=0)\n",
    "\n",
    "            BatchInd.append(SampleInd)\n",
    "        RemainIndex = np.delete(Index,Removed)\n",
    "        BatchInd.append(RemainIndex)\n",
    "\n",
    "        return BatchInd,NumBatches\n",
    "\n",
    "    def unpickle(file):\n",
    "        import pickle\n",
    "        with open(file, 'rb') as fo:\n",
    "            dict = pickle.load(fo, encoding='bytes')\n",
    "        return dict\n",
    "\n",
    "    def one_hot(label_list):\n",
    "        NumLabels = len(label_list)\n",
    "        MaxLabel = max(label_list)\n",
    "        one_hot_labels = np.zeros([NumLabels,MaxLabel+1],dtype=int)\n",
    "        for i in range(NumLabels):\n",
    "            one_hot_labels[i,label_list[i]-1] = 1\n",
    "\n",
    "        return one_hot_labels\n",
    "\n",
    "    def one_hot_reverse(one_hot_labels):\n",
    "        labels = []\n",
    "        for i in range(one_hot_labels.shape[0]):\n",
    "            Sample = one_hot_labels[i,:]\n",
    "            labels.append(Sample.argmax())\n",
    "\n",
    "        return np.asarray(labels)\n",
    "\n",
    "    InitStr = 'cifar-10-python\\cifar-10-batches-py\\data_batch_'\n",
    "    File = InitStr + np.str(1)\n",
    "    Batch = unpickle(File)\n",
    "    FullInputs = Batch[b'data']\n",
    "    FullTargets = one_hot(Batch[b'labels'])\n",
    "\n",
    "\n",
    "    for i in  range(4):\n",
    "        File = InitStr + np.str(i+2)\n",
    "        Batch = unpickle(File)\n",
    "        FullInputs = np.append(FullInputs,Batch[b'data'],axis=0)\n",
    "        FullTargets = np.append(FullTargets,one_hot(Batch[b'labels']),axis=0)\n",
    "\n",
    "    Conv = 1\n",
    "    if Conv == 1:\n",
    "        FullInputs = np.reshape(FullInputs,[FullInputs.shape[0],3,32,32]).transpose(0,2,3,1)\n",
    "\n",
    "    FullInputs = FullInputs.copy(order='C')\n",
    "\n",
    "    Validation_Cutoff = 0.75\n",
    "\n",
    "    Validation_Cutoff = np.int(Validation_Cutoff*FullInputs.shape[0])\n",
    "    if Conv == 1:\n",
    "        ValInputs = FullInputs[Validation_Cutoff:,:,:,:]\n",
    "    else:\n",
    "        ValInputs = FullInputs[Validation_Cutoff:,:]\n",
    "    ValTargets = FullTargets[Validation_Cutoff:,:]\n",
    "\n",
    "    if Conv == 1:\n",
    "        TrainInputs = FullInputs[0:Validation_Cutoff,:,:,:]\n",
    "    else:\n",
    "        TrainInputs = FullInputs[0:Validation_Cutoff,:]\n",
    "\n",
    "    TrainTargets = FullTargets[0:Validation_Cutoff,:]\n",
    "\n",
    "\n",
    "    data_dim = TrainInputs.shape[1]\n",
    "    if Conv == 1:\n",
    "        data_dim2 = TrainInputs.shape[2]\n",
    "        NumChannels = 3\n",
    "\n",
    "    NumSamples = TrainInputs.shape[0]\n",
    "    Num_Targets = TrainTargets.shape[-1]\n",
    "\n",
    "    index = np.linspace(0,NumSamples,NumSamples,endpoint=False,dtype=int)\n",
    "\n",
    "    reg_coeff = 0\n",
    "\n",
    "    def Gen_Conv_Model(reg_coeff):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(50,(3,3),activation='relu',input_shape =(data_dim,data_dim2,NumChannels),data_format=\"channels_last\"))\n",
    "        model.add(MaxPool2D())\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(50,(3,3),activation='relu',data_format=\"channels_last\"))\n",
    "        model.add(MaxPool2D())\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Flatten())\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(100,activation='relu',kernel_regularizer=l2(reg_coeff)))\n",
    "        model.add(Dropout(0.25))\n",
    "    #     model.add(Dense(100,activation='relu',kernel_regularizer=l2(reg_coeff)))\n",
    "        model.add(Dense(Num_Targets,activation = 'softmax',kernel_regularizer=l2(reg_coeff),input_shape =(data_dim,)))\n",
    "        optim = optimizers.adam(lr=0.0001)\n",
    "        model.compile(loss='categorical_crossentropy',optimizer=optim,metrics=['categorical_accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def Gen_FF_Model(reg_coeff):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(300,activation='relu',input_shape =(data_dim,),kernel_regularizer=l2(reg_coeff)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(300,activation='relu',input_shape =(data_dim,),kernel_regularizer=l2(reg_coeff)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(300,activation='relu',input_shape =(data_dim,),kernel_regularizer=l2(reg_coeff)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(Num_Targets,activation = 'softmax',kernel_regularizer=l2(reg_coeff),input_shape =(data_dim,)))\n",
    "        optim = optimizers.adagrad(lr=0.00001,decay=0.95)\n",
    "        model.compile(loss='categorical_crossentropy',optimizer=optim,metrics=['categorical_accuracy'])\n",
    "        return model\n",
    "\n",
    "    if Conv == 1:\n",
    "        Uni_model = Gen_Conv_Model(reg_coeff)\n",
    "    else:\n",
    "        Uni_model = Gen_FF_Model(reg_coeff)\n",
    "\n",
    "    Init_Weights = Uni_model.get_weights()\n",
    "\n",
    "    def acquisition_function_BALD(model,samples,Num_Targets,temperature=1,Target_Ratio = 5):\n",
    "        nb_MC_samples = 30\n",
    "        MC_output = K.function([model.layers[0].input, K.learning_phase()], [model.layers[-1].output])\n",
    "        MC_samples = np.zeros([nb_MC_samples,samples.shape[0],Num_Targets])\n",
    "        learning_phase = True \n",
    "        for i in range(nb_MC_samples):\n",
    "            MC_samples[i,:,:] = np.array([MC_output([samples, learning_phase])[0]])\n",
    "\n",
    "        expected_entropy = - np.mean(np.sum(MC_samples * np.log(MC_samples + 1e-10), axis=-1), axis=0)  # [batch size]\n",
    "        expected_p = np.mean(MC_samples, axis=0)\n",
    "        entropy_expected_p = - np.sum(expected_p * np.log(expected_p + 1e-10), axis=-1)  # [batch size]\n",
    "        BALD_acq = entropy_expected_p - expected_entropy\n",
    "\n",
    "        Exp_BALD = np.exp(BALD_acq/temperature)\n",
    "        Sampling_Prob = Exp_BALD/np.sum(Exp_BALD).astype(float)\n",
    "\n",
    "        Max_Prob_Ratio = Sampling_Prob.max()/Sampling_Prob.min()\n",
    "        Target_Ratio = Target_Ratio\n",
    "        if Max_Prob_Ratio < Target_Ratio:\n",
    "            while Max_Prob_Ratio <Target_Ratio:\n",
    "                temperature = temperature*0.99\n",
    "                Exp_BALD = np.exp(BALD_acq/temperature)\n",
    "                StoreSampling_Prob = Sampling_Prob.copy()\n",
    "                Sampling_Prob = Exp_BALD/np.sum(Exp_BALD).astype(float)\n",
    "                Max_Prob_Ratio = Sampling_Prob.max()/Sampling_Prob.min()\n",
    "                if np.isnan(Max_Prob_Ratio):\n",
    "                    Sampling_Prob = StoreSampling_Prob.copy()\n",
    "        else:\n",
    "            while Max_Prob_Ratio > Target_Ratio:\n",
    "                temperature = temperature*1.01\n",
    "                Exp_BALD = np.exp(BALD_acq/temperature)\n",
    "                StoreSampling_Prob = Sampling_Prob.copy()\n",
    "                Sampling_Prob = Exp_BALD/np.sum(Exp_BALD).astype(float)\n",
    "                Max_Prob_Ratio = Sampling_Prob.max()/Sampling_Prob.min()\n",
    "                if np.isnan(Max_Prob_Ratio):\n",
    "                    Sampling_Prob = StoreSampling_Prob.copy()\n",
    "        return Sampling_Prob\n",
    "\n",
    "\n",
    "    def acquisition_function_dist_to_threshold(model,samples,Num_Targets,temperature=1,Target_Ratio=5):\n",
    "        Output = model.predict(samples)\n",
    "        Output -= 1/float(Num_Targets)\n",
    "        Dist_to_Threshold = np.sum(np.abs(Output),1)\n",
    "        Exp_Dist_to_Threshold = np.exp(Dist_to_Threshold/temperature)\n",
    "        Exp_Dist_to_Threshold *= 1\n",
    "    #     Exp_Dist_to_Threshold = Dist_to_Threshold\n",
    "        Sampling_Prob = Exp_Dist_to_Threshold/np.sum(Exp_Dist_to_Threshold).astype(float)\n",
    "        Max_Prob_Ratio = Sampling_Prob.max()/Sampling_Prob.min()\n",
    "        Target_Ratio = Target_Ratio\n",
    "        if Max_Prob_Ratio < Target_Ratio:\n",
    "            while Max_Prob_Ratio <Target_Ratio:\n",
    "                temperature = temperature*0.99\n",
    "                Exp_Dist_to_Threshold = np.exp(Dist_to_Threshold/temperature)\n",
    "                StoreSampling_Prob = Sampling_Prob.copy()\n",
    "                Sampling_Prob = Exp_Dist_to_Threshold/np.sum(Exp_Dist_to_Threshold).astype(float)\n",
    "                Max_Prob_Ratio = Sampling_Prob.max()/Sampling_Prob.min()\n",
    "                if np.isnan(Max_Prob_Ratio):\n",
    "                    Sampling_Prob = StoreSampling_Prob.copy()\n",
    "        else:\n",
    "            while Max_Prob_Ratio > Target_Ratio:\n",
    "                temperature = temperature*1.01\n",
    "                Exp_Dist_to_Threshold = np.exp(Dist_to_Threshold/temperature)\n",
    "                StoreSampling_Prob = Sampling_Prob.copy()\n",
    "                Sampling_Prob = Exp_Dist_to_Threshold/np.sum(Exp_Dist_to_Threshold).astype(float)\n",
    "                Max_Prob_Ratio = Sampling_Prob.max()/Sampling_Prob.min()\n",
    "                if np.isnan(Max_Prob_Ratio):\n",
    "                    Sampling_Prob = StoreSampling_Prob.copy()\n",
    "        return Sampling_Prob\n",
    "\n",
    "\n",
    "    count = 0 \n",
    "    Num_Epochs = Num_Epochs\n",
    "    Num_BurnIn = 1\n",
    "    Batch_Size = 100\n",
    "\n",
    "    NumTasks = 3\n",
    "    try:\n",
    "        SwitchPoint = np.int(Num_Epochs/NumTasks)\n",
    "        print(SwitchPoint)\n",
    "    except:\n",
    "        SwitchPoint = 1\n",
    "    Smoothing_Constant = 0\n",
    "\n",
    "    Val_Error = np.zeros([Num_Epochs,4])\n",
    "    Val_Acc = np.zeros([Num_Epochs,4])\n",
    "\n",
    "    Uni_model.fit(TrainInputs,TrainTargets,batch_size = Batch_Size,epochs=Num_Epochs,verbose=1,validation_data=[ValInputs,ValTargets])\n",
    "\n",
    "    TestStr = 'cifar-10-python\\cifar-10-batches-py\\test_batch'\n",
    "\n",
    "    TestInputs = Batch[b'data']\n",
    "    TestTargets = one_hot(Batch[b'labels'])\n",
    "\n",
    "    if Conv == 1:\n",
    "        TestInputs = np.reshape(TestInputs,[TestInputs.shape[0],3,32,32]).transpose(0,2,3,1)\n",
    "\n",
    "    Predicted_Classes = Uni_model.predict_classes(TestInputs)\n",
    "    Test_Labels = one_hot_reverse(TestTargets)\n",
    "    Diff = Predicted_Classes - Test_Labels\n",
    "    Correct = Diff[Diff ==0 ]\n",
    "    Uni_TestError = Correct.shape[0]/Test_Labels.shape[0]\n",
    "\n",
    "    Dist_to_Threshold = acquisition_function_dist_to_threshold(Uni_model,TrainInputs,Num_Targets,1,10)\n",
    "\n",
    "    Easy_Dist_to_Threshold_ArgSort = np.flipud(Dist_to_Threshold.argsort())\n",
    "    Hard_Dist_to_Threshold_ArgSort = Dist_to_Threshold.argsort()\n",
    "\n",
    "    D2T_Easy_Model = Gen_Conv_Model(reg_coeff)\n",
    "    D2T_Easy_Model.set_weights(Init_Weights)\n",
    "    del Uni_model\n",
    "\n",
    "    NumTasks = Num_Tasks\n",
    "    TaskSplitPoints = np.int(np.ceil(NumSamples/NumTasks))\n",
    "    print(TaskSplitPoints)\n",
    "    for i in range(NumTasks):\n",
    "        Num_Epochs_Task = Num_Epochs*(1/(i+1))\n",
    "        TaskInd = Easy_Dist_to_Threshold_ArgSort[0:np.min([(i+1)*TaskSplitPoints,NumSamples])]\n",
    "        D2T_Easy_Model.fit(TrainInputs[TaskInd,:],TrainTargets[TaskInd],batch_size=Batch_Size,epochs = np.int(Num_Epochs_Task))\n",
    "\n",
    "    Predicted_Classes = D2T_Easy_Model.predict_classes(TestInputs)\n",
    "    Test_Labels = one_hot_reverse(TestTargets)\n",
    "    Diff = Predicted_Classes - Test_Labels\n",
    "    Correct = Diff[Diff ==0 ]\n",
    "    D2T_Easy_TestError = Correct.shape[0]/Test_Labels.shape[0]\n",
    "\n",
    "    D2T_Hard_Model = Gen_Conv_Model(reg_coeff)\n",
    "    D2T_Hard_Model.set_weights(Init_Weights)\n",
    "    del D2T_Easy_Model\n",
    "\n",
    "    NumTasks = Num_Tasks\n",
    "    TaskSplitPoints = np.int(np.ceil(NumSamples/NumTasks))\n",
    "    print(TaskSplitPoints)\n",
    "    for i in range(NumTasks):\n",
    "        Num_Epochs_Task = Num_Epochs*(1/(i+1))\n",
    "        TaskInd = Hard_Dist_to_Threshold_ArgSort[0:np.min([(i+1)*TaskSplitPoints,NumSamples])]\n",
    "        D2T_Hard_Model.fit(TrainInputs[TaskInd,:],TrainTargets[TaskInd],batch_size=Batch_Size,epochs = np.int(Num_Epochs_Task))\n",
    "\n",
    "\n",
    "    Predicted_Classes = D2T_Hard_Model.predict_classes(TestInputs)\n",
    "    Test_Labels = one_hot_reverse(TestTargets)\n",
    "    Diff = Predicted_Classes - Test_Labels\n",
    "    Correct = Diff[Diff ==0 ]\n",
    "    D2T_Hard_TestError = Correct.shape[0]/Test_Labels.shape[0]\n",
    "\n",
    "    del D2T_Hard_Model\n",
    "    \n",
    "    Errors = np.array([Uni_TestError,D2T_Hard_TestError,D2T_Easy_TestError])\n",
    "\n",
    "    return Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "4\n",
      "GPU[0] Tesla K40c\n",
      "16\n",
      "Train on 37500 samples, validate on 12500 samples\n",
      "Epoch 1/50\n",
      "37500/37500 [==============================] - 18s 473us/step - loss: 2.2037 - categorical_accuracy: 0.2874 - val_loss: 1.6455 - val_categorical_accuracy: 0.4263\n",
      "Epoch 2/50\n",
      "37500/37500 [==============================] - 18s 467us/step - loss: 1.7054 - categorical_accuracy: 0.4117 - val_loss: 1.4359 - val_categorical_accuracy: 0.4950\n",
      "Epoch 3/50\n",
      "37500/37500 [==============================] - 18s 468us/step - loss: 1.5202 - categorical_accuracy: 0.4689 - val_loss: 1.3383 - val_categorical_accuracy: 0.5296\n",
      "Epoch 4/50\n",
      "37500/37500 [==============================] - 18s 468us/step - loss: 1.3914 - categorical_accuracy: 0.5143 - val_loss: 1.2319 - val_categorical_accuracy: 0.5704\n",
      "Epoch 5/50\n",
      "37500/37500 [==============================] - 18s 467us/step - loss: 1.3060 - categorical_accuracy: 0.5398 - val_loss: 1.1772 - val_categorical_accuracy: 0.5860\n",
      "Epoch 6/50\n",
      "37500/37500 [==============================] - 18s 468us/step - loss: 1.2339 - categorical_accuracy: 0.5670 - val_loss: 1.2311 - val_categorical_accuracy: 0.5689\n",
      "Epoch 7/50\n",
      "37500/37500 [==============================] - 18s 467us/step - loss: 1.1752 - categorical_accuracy: 0.5870 - val_loss: 1.1125 - val_categorical_accuracy: 0.6120\n",
      "Epoch 8/50\n",
      "37500/37500 [==============================] - 18s 467us/step - loss: 1.1270 - categorical_accuracy: 0.6047 - val_loss: 1.1112 - val_categorical_accuracy: 0.6095\n",
      "Epoch 9/50\n",
      "37500/37500 [==============================] - 18s 467us/step - loss: 1.0803 - categorical_accuracy: 0.6209 - val_loss: 1.0405 - val_categorical_accuracy: 0.6378\n",
      "Epoch 10/50\n",
      "37500/37500 [==============================] - 18s 467us/step - loss: 1.0566 - categorical_accuracy: 0.6310 - val_loss: 1.0288 - val_categorical_accuracy: 0.6406\n",
      "Epoch 11/50\n",
      "37500/37500 [==============================] - 18s 467us/step - loss: 1.0233 - categorical_accuracy: 0.6410 - val_loss: 1.0040 - val_categorical_accuracy: 0.6505\n",
      "Epoch 12/50\n",
      "37500/37500 [==============================] - 18s 468us/step - loss: 0.9923 - categorical_accuracy: 0.6513 - val_loss: 1.0732 - val_categorical_accuracy: 0.6253\n",
      "Epoch 13/50\n",
      "37500/37500 [==============================] - 18s 467us/step - loss: 0.9651 - categorical_accuracy: 0.6603 - val_loss: 0.9722 - val_categorical_accuracy: 0.6627\n",
      "Epoch 14/50\n",
      "37500/37500 [==============================] - 18s 467us/step - loss: 0.9428 - categorical_accuracy: 0.6694 - val_loss: 0.9565 - val_categorical_accuracy: 0.6655\n",
      "Epoch 15/50\n",
      "37500/37500 [==============================] - 18s 468us/step - loss: 0.9225 - categorical_accuracy: 0.6794 - val_loss: 0.9433 - val_categorical_accuracy: 0.6698\n",
      "Epoch 16/50\n",
      "37500/37500 [==============================] - 18s 467us/step - loss: 0.8937 - categorical_accuracy: 0.6877 - val_loss: 0.9492 - val_categorical_accuracy: 0.6690\n",
      "Epoch 17/50\n",
      "37500/37500 [==============================] - 18s 468us/step - loss: 0.8709 - categorical_accuracy: 0.6948 - val_loss: 0.9505 - val_categorical_accuracy: 0.6712\n",
      "Epoch 18/50\n",
      "37500/37500 [==============================] - 18s 469us/step - loss: 0.8545 - categorical_accuracy: 0.7006 - val_loss: 0.9111 - val_categorical_accuracy: 0.6850\n",
      "Epoch 19/50\n",
      "37500/37500 [==============================] - 18s 470us/step - loss: 0.8350 - categorical_accuracy: 0.7071 - val_loss: 0.9759 - val_categorical_accuracy: 0.6620\n",
      "Epoch 20/50\n",
      "37500/37500 [==============================] - 18s 467us/step - loss: 0.8213 - categorical_accuracy: 0.7118 - val_loss: 0.9152 - val_categorical_accuracy: 0.6847\n",
      "Epoch 21/50\n",
      "37500/37500 [==============================] - 18s 467us/step - loss: 0.8044 - categorical_accuracy: 0.7147 - val_loss: 0.9376 - val_categorical_accuracy: 0.6808\n",
      "Epoch 22/50\n",
      "37500/37500 [==============================] - 18s 467us/step - loss: 0.7868 - categorical_accuracy: 0.7253 - val_loss: 0.8961 - val_categorical_accuracy: 0.6875\n",
      "Epoch 23/50\n",
      "37500/37500 [==============================] - 18s 469us/step - loss: 0.7740 - categorical_accuracy: 0.7295 - val_loss: 0.9154 - val_categorical_accuracy: 0.6819\n",
      "Epoch 24/50\n",
      "37500/37500 [==============================] - 18s 468us/step - loss: 0.7619 - categorical_accuracy: 0.7307 - val_loss: 0.9155 - val_categorical_accuracy: 0.6840\n",
      "Epoch 25/50\n",
      "37500/37500 [==============================] - 18s 468us/step - loss: 0.7457 - categorical_accuracy: 0.7366 - val_loss: 0.8879 - val_categorical_accuracy: 0.6871\n",
      "Epoch 26/50\n",
      "37500/37500 [==============================] - 18s 468us/step - loss: 0.7345 - categorical_accuracy: 0.7427 - val_loss: 0.8849 - val_categorical_accuracy: 0.6947\n",
      "Epoch 27/50\n",
      "37500/37500 [==============================] - 18s 467us/step - loss: 0.7236 - categorical_accuracy: 0.7490 - val_loss: 0.9895 - val_categorical_accuracy: 0.6617\n",
      "Epoch 28/50\n",
      "37500/37500 [==============================] - 18s 467us/step - loss: 0.7130 - categorical_accuracy: 0.7492 - val_loss: 0.9327 - val_categorical_accuracy: 0.6858\n",
      "Epoch 29/50\n",
      "37500/37500 [==============================] - 18s 468us/step - loss: 0.6946 - categorical_accuracy: 0.7579 - val_loss: 0.8918 - val_categorical_accuracy: 0.6926\n",
      "Epoch 30/50\n",
      "37500/37500 [==============================] - 18s 467us/step - loss: 0.6858 - categorical_accuracy: 0.7563 - val_loss: 0.8555 - val_categorical_accuracy: 0.7052\n",
      "Epoch 31/50\n",
      "37500/37500 [==============================] - 18s 467us/step - loss: 0.6716 - categorical_accuracy: 0.7633 - val_loss: 0.8444 - val_categorical_accuracy: 0.7065\n",
      "Epoch 32/50\n",
      "37500/37500 [==============================] - 18s 469us/step - loss: 0.6648 - categorical_accuracy: 0.7638 - val_loss: 0.8512 - val_categorical_accuracy: 0.7073\n",
      "Epoch 33/50\n",
      "37500/37500 [==============================] - 18s 467us/step - loss: 0.6542 - categorical_accuracy: 0.7709 - val_loss: 0.8530 - val_categorical_accuracy: 0.7065\n",
      "Epoch 34/50\n",
      "37500/37500 [==============================] - 18s 468us/step - loss: 0.6440 - categorical_accuracy: 0.7727 - val_loss: 0.8355 - val_categorical_accuracy: 0.7134\n",
      "Epoch 35/50\n",
      "37500/37500 [==============================] - 18s 467us/step - loss: 0.6341 - categorical_accuracy: 0.7762 - val_loss: 0.8576 - val_categorical_accuracy: 0.7063\n",
      "Epoch 36/50\n",
      "37500/37500 [==============================] - 18s 468us/step - loss: 0.6248 - categorical_accuracy: 0.7803 - val_loss: 0.9031 - val_categorical_accuracy: 0.6945\n",
      "Epoch 37/50\n",
      "37500/37500 [==============================] - 18s 467us/step - loss: 0.6147 - categorical_accuracy: 0.7832 - val_loss: 0.9049 - val_categorical_accuracy: 0.6933\n",
      "Epoch 38/50\n",
      "37500/37500 [==============================] - 18s 467us/step - loss: 0.6046 - categorical_accuracy: 0.7868 - val_loss: 0.8316 - val_categorical_accuracy: 0.7106\n",
      "Epoch 39/50\n",
      "37500/37500 [==============================] - 18s 468us/step - loss: 0.6028 - categorical_accuracy: 0.7878 - val_loss: 0.8488 - val_categorical_accuracy: 0.7035\n",
      "Epoch 40/50\n",
      "37500/37500 [==============================] - 18s 467us/step - loss: 0.5848 - categorical_accuracy: 0.7923 - val_loss: 0.8286 - val_categorical_accuracy: 0.7142\n",
      "Epoch 41/50\n",
      "37500/37500 [==============================] - 18s 468us/step - loss: 0.5789 - categorical_accuracy: 0.7980 - val_loss: 0.8282 - val_categorical_accuracy: 0.7155\n",
      "Epoch 42/50\n",
      "37500/37500 [==============================] - 18s 467us/step - loss: 0.5733 - categorical_accuracy: 0.7974 - val_loss: 0.9124 - val_categorical_accuracy: 0.6902\n",
      "Epoch 43/50\n",
      "37500/37500 [==============================] - 18s 467us/step - loss: 0.5599 - categorical_accuracy: 0.8026 - val_loss: 0.8485 - val_categorical_accuracy: 0.7071\n",
      "Epoch 44/50\n",
      "37500/37500 [==============================] - 18s 467us/step - loss: 0.5561 - categorical_accuracy: 0.8040 - val_loss: 0.8402 - val_categorical_accuracy: 0.7163\n",
      "Epoch 45/50\n",
      "37500/37500 [==============================] - 18s 467us/step - loss: 0.5451 - categorical_accuracy: 0.8062 - val_loss: 0.8511 - val_categorical_accuracy: 0.7112\n",
      "Epoch 46/50\n",
      "37500/37500 [==============================] - 18s 467us/step - loss: 0.5409 - categorical_accuracy: 0.8081 - val_loss: 0.8236 - val_categorical_accuracy: 0.7197\n",
      "Epoch 47/50\n",
      "37500/37500 [==============================] - 18s 467us/step - loss: 0.5396 - categorical_accuracy: 0.8080 - val_loss: 0.8809 - val_categorical_accuracy: 0.7072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50\n",
      "37500/37500 [==============================] - 18s 467us/step - loss: 0.5263 - categorical_accuracy: 0.8133 - val_loss: 0.9227 - val_categorical_accuracy: 0.6929\n",
      "Epoch 49/50\n",
      "37500/37500 [==============================] - 18s 467us/step - loss: 0.5208 - categorical_accuracy: 0.8160 - val_loss: 0.8383 - val_categorical_accuracy: 0.7194\n",
      "Epoch 50/50\n",
      "37500/37500 [==============================] - 18s 468us/step - loss: 0.5155 - categorical_accuracy: 0.8169 - val_loss: 0.8940 - val_categorical_accuracy: 0.6990\n",
      "7500\n",
      "Epoch 1/50\n",
      "7500/7500 [==============================] - 3s 453us/step - loss: 1.9427 - categorical_accuracy: 0.3939\n",
      "Epoch 2/50\n",
      "7500/7500 [==============================] - 3s 431us/step - loss: 1.1657 - categorical_accuracy: 0.6267\n",
      "Epoch 3/50\n",
      "7500/7500 [==============================] - 3s 428us/step - loss: 0.9143 - categorical_accuracy: 0.7076\n",
      "Epoch 4/50\n",
      "7500/7500 [==============================] - 3s 428us/step - loss: 0.7384 - categorical_accuracy: 0.7573\n",
      "Epoch 5/50\n",
      "7500/7500 [==============================] - 3s 429us/step - loss: 0.6265 - categorical_accuracy: 0.7933\n",
      "Epoch 6/50\n",
      "7500/7500 [==============================] - 3s 429us/step - loss: 0.5324 - categorical_accuracy: 0.8268\n",
      "Epoch 7/50\n",
      "7500/7500 [==============================] - 3s 428us/step - loss: 0.4545 - categorical_accuracy: 0.8516\n",
      "Epoch 8/50\n",
      "7500/7500 [==============================] - 3s 428us/step - loss: 0.4098 - categorical_accuracy: 0.8707\n",
      "Epoch 9/50\n",
      "7500/7500 [==============================] - 3s 427us/step - loss: 0.3628 - categorical_accuracy: 0.8807\n",
      "Epoch 10/50\n",
      "7500/7500 [==============================] - 3s 428us/step - loss: 0.3186 - categorical_accuracy: 0.8981\n",
      "Epoch 11/50\n",
      "7500/7500 [==============================] - 3s 428us/step - loss: 0.2863 - categorical_accuracy: 0.9067\n",
      "Epoch 12/50\n",
      "7500/7500 [==============================] - 3s 429us/step - loss: 0.2573 - categorical_accuracy: 0.9160\n",
      "Epoch 13/50\n",
      "7500/7500 [==============================] - 3s 428us/step - loss: 0.2339 - categorical_accuracy: 0.9276\n",
      "Epoch 14/50\n",
      "7500/7500 [==============================] - 3s 429us/step - loss: 0.2195 - categorical_accuracy: 0.9272\n",
      "Epoch 15/50\n",
      "7500/7500 [==============================] - 3s 428us/step - loss: 0.1949 - categorical_accuracy: 0.9361\n",
      "Epoch 16/50\n",
      "7500/7500 [==============================] - 3s 428us/step - loss: 0.1732 - categorical_accuracy: 0.9432\n",
      "Epoch 17/50\n",
      "7500/7500 [==============================] - 3s 428us/step - loss: 0.1601 - categorical_accuracy: 0.9487\n",
      "Epoch 18/50\n",
      "7500/7500 [==============================] - 3s 427us/step - loss: 0.1529 - categorical_accuracy: 0.9499\n",
      "Epoch 19/50\n",
      "7500/7500 [==============================] - 3s 428us/step - loss: 0.1371 - categorical_accuracy: 0.9591\n",
      "Epoch 20/50\n",
      "7500/7500 [==============================] - 3s 428us/step - loss: 0.1251 - categorical_accuracy: 0.9615\n",
      "Epoch 21/50\n",
      "7500/7500 [==============================] - 3s 428us/step - loss: 0.1163 - categorical_accuracy: 0.9652\n",
      "Epoch 22/50\n",
      "7500/7500 [==============================] - 3s 428us/step - loss: 0.1097 - categorical_accuracy: 0.9645\n",
      "Epoch 23/50\n",
      "7500/7500 [==============================] - 3s 428us/step - loss: 0.1006 - categorical_accuracy: 0.9692\n",
      "Epoch 24/50\n",
      "7500/7500 [==============================] - 3s 428us/step - loss: 0.0997 - categorical_accuracy: 0.9699\n",
      "Epoch 25/50\n",
      "7500/7500 [==============================] - 3s 428us/step - loss: 0.0914 - categorical_accuracy: 0.9727\n",
      "Epoch 26/50\n",
      "7500/7500 [==============================] - 3s 428us/step - loss: 0.0834 - categorical_accuracy: 0.9741\n",
      "Epoch 27/50\n",
      "7500/7500 [==============================] - 3s 429us/step - loss: 0.0845 - categorical_accuracy: 0.9756\n",
      "Epoch 28/50\n",
      "7500/7500 [==============================] - 3s 428us/step - loss: 0.0729 - categorical_accuracy: 0.9763\n",
      "Epoch 29/50\n",
      "7500/7500 [==============================] - 3s 428us/step - loss: 0.0709 - categorical_accuracy: 0.9785\n",
      "Epoch 30/50\n",
      "7500/7500 [==============================] - 3s 429us/step - loss: 0.0652 - categorical_accuracy: 0.9813\n",
      "Epoch 31/50\n",
      "7500/7500 [==============================] - 3s 429us/step - loss: 0.0621 - categorical_accuracy: 0.9825\n",
      "Epoch 32/50\n",
      "7500/7500 [==============================] - 3s 427us/step - loss: 0.0583 - categorical_accuracy: 0.9840\n",
      "Epoch 33/50\n",
      "7500/7500 [==============================] - 3s 428us/step - loss: 0.0550 - categorical_accuracy: 0.9837\n",
      "Epoch 34/50\n",
      "7500/7500 [==============================] - 3s 428us/step - loss: 0.0502 - categorical_accuracy: 0.9849\n",
      "Epoch 35/50\n",
      "7500/7500 [==============================] - 3s 428us/step - loss: 0.0458 - categorical_accuracy: 0.9879\n",
      "Epoch 36/50\n",
      "7500/7500 [==============================] - 3s 428us/step - loss: 0.0480 - categorical_accuracy: 0.9860\n",
      "Epoch 37/50\n",
      "7500/7500 [==============================] - 3s 428us/step - loss: 0.0458 - categorical_accuracy: 0.9875\n",
      "Epoch 38/50\n",
      "7500/7500 [==============================] - 3s 428us/step - loss: 0.0392 - categorical_accuracy: 0.9913\n",
      "Epoch 39/50\n",
      "7500/7500 [==============================] - 3s 430us/step - loss: 0.0391 - categorical_accuracy: 0.9883\n",
      "Epoch 40/50\n",
      "7500/7500 [==============================] - 3s 429us/step - loss: 0.0384 - categorical_accuracy: 0.9879\n",
      "Epoch 41/50\n",
      "7500/7500 [==============================] - 3s 431us/step - loss: 0.0352 - categorical_accuracy: 0.9901\n",
      "Epoch 42/50\n",
      "7500/7500 [==============================] - 3s 429us/step - loss: 0.0351 - categorical_accuracy: 0.9905\n",
      "Epoch 43/50\n",
      "7500/7500 [==============================] - 3s 429us/step - loss: 0.0314 - categorical_accuracy: 0.9920\n",
      "Epoch 44/50\n",
      "7500/7500 [==============================] - 3s 428us/step - loss: 0.0315 - categorical_accuracy: 0.9921\n",
      "Epoch 45/50\n",
      "7500/7500 [==============================] - 3s 428us/step - loss: 0.0320 - categorical_accuracy: 0.9913\n",
      "Epoch 46/50\n",
      "7500/7500 [==============================] - 3s 428us/step - loss: 0.0299 - categorical_accuracy: 0.9921\n",
      "Epoch 47/50\n",
      "7500/7500 [==============================] - 3s 429us/step - loss: 0.0243 - categorical_accuracy: 0.9945\n",
      "Epoch 48/50\n",
      "7500/7500 [==============================] - 3s 430us/step - loss: 0.0267 - categorical_accuracy: 0.9928\n",
      "Epoch 49/50\n",
      "7500/7500 [==============================] - 3s 429us/step - loss: 0.0244 - categorical_accuracy: 0.9941\n",
      "Epoch 50/50\n",
      "7500/7500 [==============================] - 3s 428us/step - loss: 0.0229 - categorical_accuracy: 0.9953\n",
      "Epoch 1/25\n",
      "15000/15000 [==============================] - 6s 428us/step - loss: 0.4285 - categorical_accuracy: 0.8797\n",
      "Epoch 2/25\n",
      "15000/15000 [==============================] - 6s 428us/step - loss: 0.3176 - categorical_accuracy: 0.9017\n",
      "Epoch 3/25\n",
      "15000/15000 [==============================] - 6s 428us/step - loss: 0.2700 - categorical_accuracy: 0.9137\n",
      "Epoch 4/25\n",
      "15000/15000 [==============================] - 6s 428us/step - loss: 0.2311 - categorical_accuracy: 0.9235\n",
      "Epoch 5/25\n",
      "15000/15000 [==============================] - 6s 428us/step - loss: 0.2119 - categorical_accuracy: 0.9289\n",
      "Epoch 6/25\n",
      "15000/15000 [==============================] - 6s 429us/step - loss: 0.1903 - categorical_accuracy: 0.9345\n",
      "Epoch 7/25\n",
      "15000/15000 [==============================] - 6s 428us/step - loss: 0.1706 - categorical_accuracy: 0.9438\n",
      "Epoch 8/25\n",
      "15000/15000 [==============================] - 6s 429us/step - loss: 0.1623 - categorical_accuracy: 0.9460\n",
      "Epoch 9/25\n",
      "15000/15000 [==============================] - 6s 430us/step - loss: 0.1489 - categorical_accuracy: 0.9505\n",
      "Epoch 10/25\n",
      "15000/15000 [==============================] - 6s 432us/step - loss: 0.1412 - categorical_accuracy: 0.9537\n",
      "Epoch 11/25\n",
      "15000/15000 [==============================] - 6s 429us/step - loss: 0.1272 - categorical_accuracy: 0.9588\n",
      "Epoch 12/25\n",
      "15000/15000 [==============================] - 6s 428us/step - loss: 0.1351 - categorical_accuracy: 0.9551\n",
      "Epoch 13/25\n",
      "15000/15000 [==============================] - 6s 428us/step - loss: 0.1176 - categorical_accuracy: 0.9611\n",
      "Epoch 14/25\n",
      "15000/15000 [==============================] - 6s 428us/step - loss: 0.1155 - categorical_accuracy: 0.9619\n",
      "Epoch 15/25\n",
      "15000/15000 [==============================] - 6s 428us/step - loss: 0.1085 - categorical_accuracy: 0.9659\n",
      "Epoch 16/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 6s 428us/step - loss: 0.1039 - categorical_accuracy: 0.9668\n",
      "Epoch 17/25\n",
      "15000/15000 [==============================] - 6s 428us/step - loss: 0.0936 - categorical_accuracy: 0.9693\n",
      "Epoch 18/25\n",
      "15000/15000 [==============================] - 6s 428us/step - loss: 0.0905 - categorical_accuracy: 0.9703\n",
      "Epoch 19/25\n",
      "15000/15000 [==============================] - 6s 428us/step - loss: 0.0834 - categorical_accuracy: 0.9736\n",
      "Epoch 20/25\n",
      "15000/15000 [==============================] - 6s 428us/step - loss: 0.0792 - categorical_accuracy: 0.9749\n",
      "Epoch 21/25\n",
      "15000/15000 [==============================] - 6s 428us/step - loss: 0.0793 - categorical_accuracy: 0.9755\n",
      "Epoch 22/25\n",
      "15000/15000 [==============================] - 6s 428us/step - loss: 0.0740 - categorical_accuracy: 0.9764\n",
      "Epoch 23/25\n",
      "15000/15000 [==============================] - 6s 428us/step - loss: 0.0740 - categorical_accuracy: 0.9763\n",
      "Epoch 24/25\n",
      "15000/15000 [==============================] - 6s 428us/step - loss: 0.0661 - categorical_accuracy: 0.9796\n",
      "Epoch 25/25\n",
      "15000/15000 [==============================] - 6s 429us/step - loss: 0.0683 - categorical_accuracy: 0.9773\n",
      "Epoch 1/16\n",
      "22500/22500 [==============================] - 10s 428us/step - loss: 0.5263 - categorical_accuracy: 0.8534\n",
      "Epoch 2/16\n",
      "22500/22500 [==============================] - 10s 428us/step - loss: 0.4301 - categorical_accuracy: 0.8653\n",
      "Epoch 3/16\n",
      "22500/22500 [==============================] - 10s 429us/step - loss: 0.3828 - categorical_accuracy: 0.8776\n",
      "Epoch 4/16\n",
      "22500/22500 [==============================] - 10s 428us/step - loss: 0.3576 - categorical_accuracy: 0.8808\n",
      "Epoch 5/16\n",
      "22500/22500 [==============================] - 10s 428us/step - loss: 0.3377 - categorical_accuracy: 0.8857\n",
      "Epoch 6/16\n",
      "22500/22500 [==============================] - 10s 428us/step - loss: 0.3149 - categorical_accuracy: 0.8946\n",
      "Epoch 7/16\n",
      "22500/22500 [==============================] - 10s 428us/step - loss: 0.3048 - categorical_accuracy: 0.8963\n",
      "Epoch 8/16\n",
      "22500/22500 [==============================] - 10s 428us/step - loss: 0.2870 - categorical_accuracy: 0.9022\n",
      "Epoch 9/16\n",
      "22500/22500 [==============================] - 10s 428us/step - loss: 0.2779 - categorical_accuracy: 0.9064\n",
      "Epoch 10/16\n",
      "22500/22500 [==============================] - 10s 429us/step - loss: 0.2664 - categorical_accuracy: 0.9070\n",
      "Epoch 11/16\n",
      "22500/22500 [==============================] - 10s 429us/step - loss: 0.2630 - categorical_accuracy: 0.9102\n",
      "Epoch 12/16\n",
      "22500/22500 [==============================] - 10s 428us/step - loss: 0.2507 - categorical_accuracy: 0.9137\n",
      "Epoch 13/16\n",
      "22500/22500 [==============================] - 10s 428us/step - loss: 0.2389 - categorical_accuracy: 0.9184\n",
      "Epoch 14/16\n",
      "22500/22500 [==============================] - 10s 429us/step - loss: 0.2299 - categorical_accuracy: 0.9220\n",
      "Epoch 15/16\n",
      "22500/22500 [==============================] - 10s 429us/step - loss: 0.2209 - categorical_accuracy: 0.9223\n",
      "Epoch 16/16\n",
      "22500/22500 [==============================] - 10s 429us/step - loss: 0.2205 - categorical_accuracy: 0.9245\n",
      "Epoch 1/12\n",
      "30000/30000 [==============================] - 13s 430us/step - loss: 0.6238 - categorical_accuracy: 0.8106\n",
      "Epoch 2/12\n",
      "30000/30000 [==============================] - 13s 429us/step - loss: 0.5621 - categorical_accuracy: 0.8205\n",
      "Epoch 3/12\n",
      "30000/30000 [==============================] - 13s 429us/step - loss: 0.5298 - categorical_accuracy: 0.8251\n",
      "Epoch 4/12\n",
      "30000/30000 [==============================] - 13s 429us/step - loss: 0.5030 - categorical_accuracy: 0.8351\n",
      "Epoch 5/12\n",
      "30000/30000 [==============================] - 13s 429us/step - loss: 0.4825 - categorical_accuracy: 0.8372\n",
      "Epoch 6/12\n",
      "30000/30000 [==============================] - 13s 429us/step - loss: 0.4657 - categorical_accuracy: 0.8429\n",
      "Epoch 7/12\n",
      "30000/30000 [==============================] - 13s 429us/step - loss: 0.4502 - categorical_accuracy: 0.8461\n",
      "Epoch 8/12\n",
      "30000/30000 [==============================] - 13s 429us/step - loss: 0.4380 - categorical_accuracy: 0.8502\n",
      "Epoch 9/12\n",
      "30000/30000 [==============================] - 13s 429us/step - loss: 0.4247 - categorical_accuracy: 0.8549\n",
      "Epoch 10/12\n",
      "30000/30000 [==============================] - 13s 429us/step - loss: 0.4163 - categorical_accuracy: 0.8565\n",
      "Epoch 11/12\n",
      "30000/30000 [==============================] - 13s 428us/step - loss: 0.4047 - categorical_accuracy: 0.8598\n",
      "Epoch 12/12\n",
      "30000/30000 [==============================] - 13s 430us/step - loss: 0.3938 - categorical_accuracy: 0.8646\n",
      "Epoch 1/10\n",
      "37500/37500 [==============================] - 16s 429us/step - loss: 0.8121 - categorical_accuracy: 0.7472\n",
      "Epoch 2/10\n",
      " 9700/37500 [======>.......................] - ETA: 11s - loss: 0.7778 - categorical_accuracy: 0.7519"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "NumTests = 100\n",
    "from IPython.display import clear_output\n",
    "\n",
    "TestError_Record = np.zeros([3,NumTests])\n",
    "\n",
    "for i in range(NumTests):\n",
    "    clear_output()\n",
    "    print('Run:')\n",
    "    print(i)\n",
    "    TestError_Record[:,i] = CIFAR_Bootstrap_Exp(5,50)\n",
    "    np.save('CIFAR_Bootstrap_Perf_5',TestError_Record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
