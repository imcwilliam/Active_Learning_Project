\begin{thebibliography}{10}

\bibitem{Allgoer1980}
E.~Allgower and K.~Georg.
\newblock {\em Numerical continuation methods. An introduction}.
\newblock Springer-Verlag, 1980.

\bibitem{avramova2015curriculum}
V.~Avramova.
\newblock Curriculum learning with deep convolutional neural networks, 2015.

\bibitem{balcan2006agnostic}
M.-F. Balcan, A.~Beygelzimer, and J.~Langford.
\newblock Agnostic active learning.
\newblock In {\em Proceedings of the 23rd international conference on Machine
  learning}, pages 65--72. ACM, 2006.

\bibitem{balcan2010true}
M.-F. Balcan, S.~Hanneke, and J.~W. Vaughan.
\newblock The true sample complexity of active learning.
\newblock {\em Machine learning}, 80(2-3):111--139, 2010.

\bibitem{bengio2012practical}
Y.~Bengio.
\newblock Practical recommendations for gradient-based training of deep
  architectures.
\newblock In {\em Neural networks: Tricks of the trade}, pages 437--478.
  Springer, 2012.

\bibitem{Bengio2009}
Y.~Bengio, J.~Louradour, R.~Collobert, and J.~Weston.
\newblock Curriculum learning.
\newblock {\em Procedures of the International Conference on Machine Learning},
  26:41--48, 2009.

\bibitem{GeoShapes}
O.~Breuleux, J.~Louradour, and F.~Bastien.
\newblock Geometric shapes database.
\newblock 2008.

\bibitem{Chang18}
H.-S. Chang, E.~Learned-Miller, and A.~McCallum.
\newblock Active bias: Training more accuracy neural networks by emphasizing
  high variance samples.
\newblock {\em Advances in Neural Information Processing Systems}, 31:1--122,
  2017.

\bibitem{chollet2015keras}
F.~Chollet et~al.
\newblock Keras, 2015.

\bibitem{cohn1994improving}
D.~Cohn, L.~Atlas, and R.~Ladner.
\newblock Improving generalization with active learning.
\newblock {\em Machine learning}, 15(2):201--221, 1994.

\bibitem{cohn1996active}
D.~A. Cohn, Z.~Ghahramani, and M.~I. Jordan.
\newblock Active learning with statistical models.
\newblock {\em Journal of artificial intelligence research}, 4:129--145, 1996.

\bibitem{ELMAN199371}
J.~L. Elman.
\newblock Learning and development in neural networks: the importance of
  starting small.
\newblock {\em Cognition}, 48(1):71 -- 99, 1993.

\bibitem{erhan2009difficulty}
D.~Erhan, P.-A. Manzagol, Y.~Bengio, S.~Bengio, and P.~Vincent.
\newblock The difficulty of training deep architectures and the effect of
  unsupervised pre-training.
\newblock In {\em Artificial Intelligence and Statistics}, pages 153--160,
  2009.

\bibitem{felzenszwalb2008discriminatively}
P.~Felzenszwalb, D.~McAllester, and D.~Ramanan.
\newblock A discriminatively trained, multiscale, deformable part model.
\newblock In {\em Computer Vision and Pattern Recognition, 2008. CVPR 2008.
  IEEE Conference on}, pages 1--8. IEEE, 2008.

\bibitem{gal2016uncertainty}
Y.~Gal.
\newblock Uncertainty in deep learning.
\newblock {\em University of Cambridge}, 2016.

\bibitem{gal2016dropout}
Y.~Gal and Z.~Ghahramani.
\newblock Dropout as a bayesian approximation: Representing model uncertainty
  in deep learning.
\newblock In {\em international conference on machine learning}, pages
  1050--1059, 2016.

\bibitem{gal2017deep}
Y.~Gal, R.~Islam, and Z.~Ghahramani.
\newblock Deep bayesian active learning with image data.
\newblock {\em arXiv preprint arXiv:1703.02910}, 2017.

\bibitem{ghosh2012outliers}
D.~Ghosh and A.~Vogt.
\newblock Outliers: An evaluation of methodologies.
\newblock In {\em Joint statistical meetings}, pages 3455--3460. American
  Statistical Association San Diego, CA, 2012.

\bibitem{graves2017automated}
A.~Graves, M.~G. Bellemare, J.~Menick, R.~Munos, and K.~Kavukcuoglu.
\newblock Automated curriculum learning for neural networks.
\newblock {\em arXiv preprint arXiv:1704.03003}, 2017.

\bibitem{grunwaldminimum}
P.~Grunwald.
\newblock The minimum description length principle. 2007.
\newblock {\em Cambridge: Massachusetts Institute of Technology}, 2007.

\bibitem{hastie2009unsupervised}
T.~Hastie, R.~Tibshirani, and J.~Friedman.
\newblock Unsupervised learning.
\newblock In {\em The elements of statistical learning}, pages 485--585.
  Springer, 2009.

\bibitem{hearst1998support}
M.~A. Hearst, S.~T. Dumais, E.~Osuna, J.~Platt, and B.~Scholkopf.
\newblock Support vector machines.
\newblock {\em IEEE Intelligent Systems and their applications}, 13(4):18--28,
  1998.

\bibitem{hinton2005kind}
G.~E. Hinton et~al.
\newblock What kind of graphical model is the brain?
\newblock In {\em IJCAI}, volume~5, pages 1765--1775, 2005.

\bibitem{houlsby2011bayesian}
N.~Houlsby, F.~Husz{\'a}r, Z.~Ghahramani, and M.~Lengyel.
\newblock Bayesian active learning for classification and preference learning.
\newblock {\em arXiv preprint arXiv:1112.5745}, 2011.

\bibitem{ioffe2015batch}
S.~Ioffe and C.~Szegedy.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock {\em arXiv preprint arXiv:1502.03167}, 2015.

\bibitem{jiang2014self}
L.~Jiang, D.~Meng, S.-I. Yu, Z.~Lan, S.~Shan, and A.~Hauptmann.
\newblock Self-paced learning with diversity.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2078--2086, 2014.

\bibitem{jiang2015self}
L.~Jiang, D.~Meng, Q.~Zhao, S.~Shan, and A.~G. Hauptmann.
\newblock Self-paced curriculum learning.
\newblock In {\em AAAI}, volume~2, page~6, 2015.

\bibitem{kingma2014adam}
D.~P. Kingma and J.~Ba.
\newblock Adam: A method for stochastic optimization.
\newblock {\em arXiv preprint arXiv:1412.6980}, 2014.

\bibitem{kneser1995improved}
R.~Kneser and H.~Ney.
\newblock Improved backing-off for m-gram language modeling.
\newblock In {\em icassp}, volume~1, page 181e4, 1995.

\bibitem{krizhevsky2009learning}
A.~Krizhevsky and G.~Hinton.
\newblock Learning multiple layers of features from tiny images.
\newblock Technical report, Citeseer, 2009.

\bibitem{kumar2010self}
M.~P. Kumar, B.~Packer, and D.~Koller.
\newblock Self-paced learning for latent variable models.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1189--1197, 2010.

\bibitem{lecun2015deep}
Y.~LeCun, Y.~Bengio, and G.~Hinton.
\newblock Deep learning.
\newblock {\em nature}, 521(7553):436, 2015.

\bibitem{lecun-mnisthandwrittendigit-2010}
Y.~LeCun and C.~Cortes.
\newblock {MNIST} handwritten digit database.
\newblock 2010.

\bibitem{lecun1988theoretical}
Y.~LeCun, D.~Touresky, G.~Hinton, and T.~Sejnowski.
\newblock A theoretical framework for back-propagation.
\newblock In {\em Proceedings of the 1988 connectionist models summer school},
  volume~1, pages 21--28. CMU, Pittsburgh, Pa: Morgan Kaufmann, 1988.

\bibitem{louradour2014curriculum}
J.~Louradour and C.~Kermorvant.
\newblock Curriculum learning for handwritten text line recognition.
\newblock In {\em Document Analysis Systems (DAS), 2014 11th IAPR International
  Workshop on}, pages 56--60. IEEE, 2014.

\bibitem{mikolov2010recurrent}
T.~Mikolov, M.~Karafi{\'a}t, L.~Burget, J.~{\v{C}}ernock{\`y}, and
  S.~Khudanpur.
\newblock Recurrent neural network based language model.
\newblock In {\em Eleventh Annual Conference of the International Speech
  Communication Association}, 2010.

\bibitem{murphy2012machine}
K.~P. Murphy.
\newblock Machine learning: A probabilistic perspective. adaptive computation
  and machine learning, 2012.

\bibitem{nagi2011max}
J.~Nagi, F.~Ducatelle, G.~A. Di~Caro, D.~Cire{\c{s}}an, U.~Meier, A.~Giusti,
  F.~Nagi, J.~Schmidhuber, and L.~M. Gambardella.
\newblock Max-pooling convolutional neural networks for vision-based hand
  gesture recognition.
\newblock In {\em Signal and Image Processing Applications (ICSIPA), 2011 IEEE
  International Conference on}, pages 342--347. IEEE, 2011.

\bibitem{nair2010rectified}
V.~Nair and G.~E. Hinton.
\newblock Rectified linear units improve restricted boltzmann machines.
\newblock In {\em Proceedings of the 27th international conference on machine
  learning (ICML-10)}, pages 807--814, 2010.

\bibitem{pan2010survey}
S.~J. Pan, Q.~Yang, et~al.
\newblock A survey on transfer learning.
\newblock {\em IEEE Transactions on knowledge and data engineering},
  22(10):1345--1359, 2010.

\bibitem{pentina2015curriculum}
A.~Pentina, V.~Sharmanska, and C.~H. Lampert.
\newblock Curriculum learning of multiple tasks.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 5492--5500, 2015.

\bibitem{ruder2016overview}
S.~Ruder.
\newblock An overview of gradient descent optimization algorithms.
\newblock {\em arXiv preprint arXiv:1609.04747}, 2016.

\bibitem{settles2012active}
B.~Settles.
\newblock Active learning.
\newblock {\em Synthesis Lectures on Artificial Intelligence and Machine
  Learning}, 6(1):1--114, 2012.

\bibitem{shamir2013stochastic}
O.~Shamir and T.~Zhang.
\newblock Stochastic gradient descent for non-smooth optimization: Convergence
  results and optimal averaging schemes.
\newblock In {\em International Conference on Machine Learning}, pages 71--79,
  2013.

\bibitem{srivastava2014dropout}
N.~Srivastava, G.~Hinton, A.~Krizhevsky, I.~Sutskever, and R.~Salakhutdinov.
\newblock Dropout: a simple way to prevent neural networks from overfitting.
\newblock {\em The Journal of Machine Learning Research}, 15(1):1929--1958,
  2014.

\bibitem{Theodoridis2009}
S.Theodoridis and K.Koutroumbas.
\newblock {\em Pattern Recognition}.
\newblock Academic Press, 4 edition, 2009.

\bibitem{sutskever2013importance}
I.~Sutskever, J.~Martens, G.~Dahl, and G.~Hinton.
\newblock On the importance of initialization and momentum in deep learning.
\newblock In {\em International conference on machine learning}, pages
  1139--1147, 2013.

\bibitem{sutton1998introduction}
R.~S. Sutton and A.~G. Barto.
\newblock {\em Introduction to reinforcement learning}, volume 135.
\newblock MIT press Cambridge, 1998.

\bibitem{tong2001support}
S.~Tong and D.~Koller.
\newblock Support vector machine active learning with applications to text
  classification.
\newblock {\em Journal of machine learning research}, 2(Nov):45--66, 2001.

\bibitem{vilalta2002perspective}
R.~Vilalta and Y.~Drissi.
\newblock A perspective view and survey of meta-learning.
\newblock {\em Artificial Intelligence Review}, 18(2):77--95, 2002.

\bibitem{wang2017cost}
K.~Wang, D.~Zhang, Y.~Li, R.~Zhang, and L.~Lin.
\newblock Cost-effective active learning for deep image classification.
\newblock {\em IEEE Transactions on Circuits and Systems for Video Technology},
  27(12):2591--2600, 2017.

\bibitem{weinshall2018curriculum}
D.~Weinshall and G.~Cohen.
\newblock Curriculum learning by transfer learning: Theory and experiments with
  deep networks.
\newblock {\em arXiv preprint arXiv:1802.03796}, 2018.

\bibitem{Witten2011}
I.~Witten, E.~Frank, and M.~Hall.
\newblock {\em DATA MINING. Practical Machine Learning Tools and Techniques}.
\newblock Morgan Kaufman, 3 edition, 2011.

\bibitem{yang2003automatically}
J.~Yang et~al.
\newblock Automatically labeling video data using multi-class active learning.
\newblock In {\em Computer Vision, 2003. Proceedings. Ninth IEEE International
  Conference on}, pages 516--523. IEEE, 2003.

\end{thebibliography}
