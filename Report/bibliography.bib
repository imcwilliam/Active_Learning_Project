%CIFAR
@techreport{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey},
  year={2009},
  institution={Citeseer},
  url = {http://www.cs.toronto.edu/~kriz/cifar.html},
  urldate = {01/06/2018},
}
%MNIST
@article{lecun-mnisthandwrittendigit-2010,
  author = {LeCun, Yann and Cortes, Corinna},
  title = {{MNIST} handwritten digit database},
  url = {http://yann.lecun.com/exdb/mnist/},
  urldate = {01/05/2018},
  year = 2010,
}

%GeoShapes
@article{GeoShapes,
  author = {O.Breuleux, J.Louradour and F.Bastien},
  title = {Geometric Shapes database},
  url = {http://www.iro.umontreal.ca/~lisa/twiki/bin/view.cgi/Public/BabyAIShapesDatasets},
  urldate = {01/05/2018},
  year = 2008,
}

%Continuation Methods
@book{Allgoer1980,
  author        = "E.L.Allgower and K.Georg",
  title         	= "Numerical continuation methods. An introduction",
  publisher   	= "Springer-Verlag",
  year        	= "1980",
}
%RNN
@inproceedings{mikolov2010recurrent,
  title={Recurrent neural network based language model},
  author={Mikolov, Tom{\'a}{\v{s}} and Karafi{\'a}t, Martin and Burget, Luk{\'a}{\v{s}} and {\v{C}}ernock{\`y}, Jan and Khudanpur, Sanjeev},
  booktitle={Eleventh Annual Conference of the International Speech Communication Association},
  year={2010}
}

%Curriculum Learning by Transfer learning
@article{weinshall2018curriculum,
  title={Curriculum Learning by Transfer Learning: Theory and Experiments with Deep Networks},
  author={Weinshall, Daphna and Cohen, Gad},
  journal={arXiv preprint arXiv:1802.03796},
  year={2018}
}

%SGD
@inproceedings{shamir2013stochastic,
  title={Stochastic gradient descent for non-smooth optimization: Convergence results and optimal averaging schemes},
  author={Shamir, Ohad and Zhang, Tong},
  booktitle={International Conference on Machine Learning},
  pages={71--79},
  year={2013}
}
%Momentum
@inproceedings{sutskever2013importance,
  title={On the importance of initialization and momentum in deep learning},
  author={Sutskever, Ilya and Martens, James and Dahl, George and Hinton, Geoffrey},
  booktitle={International conference on machine learning},
  pages={1139--1147},
  year={2013}
}

%Deep Learning
@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436},
  year={2015},
  publisher={Nature Publishing Group}
}

%Batch Norm
@article{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  journal={arXiv preprint arXiv:1502.03167},
  year={2015}
}

%Dropout
@article{srivastava2014dropout,
  title={Dropout: a simple way to prevent neural networks from overfitting},
  author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={The Journal of Machine Learning Research},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014},
  publisher={JMLR. org}
}

%Unsupervised Pre-Training
@article{erhan2010does,
  title={Why does unsupervised pre-training help deep learning?},
  author={Erhan, Dumitru and Bengio, Yoshua and Courville, Aaron and Manzagol, Pierre-Antoine and Vincent, Pascal and Bengio, Samy},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={Feb},
  pages={625--660},
  year={2010}
}

@inproceedings{erhan2009difficulty,
  title={The difficulty of training deep architectures and the effect of unsupervised pre-training},
  author={Erhan, Dumitru and Manzagol, Pierre-Antoine and Bengio, Yoshua and Bengio, Samy and Vincent, Pascal},
  booktitle={Artificial Intelligence and Statistics},
  pages={153--160},
  year={2009}
}

%Transfer Learning
@article{pan2010survey,
  title={A survey on transfer learning},
  author={Pan, Sinno Jialin and Yang, Qiang and others},
  journal={IEEE Transactions on knowledge and data engineering},
  volume={22},
  number={10},
  pages={1345--1359},
  year={2010},
  publisher={Institute of Electrical and Electronics Engineers, Inc., 345 E. 47 th St. NY NY 10017-2394 USA}
}

%Curriculum Learning
@incollection{bengio2012practical,
  title={Practical recommendations for gradient-based training of deep architectures},
  author={Bengio, Yoshua},
  booktitle={Neural networks: Tricks of the trade},
  pages={437--478},
  year={2012},
  publisher={Springer}
}
%Curriculum Learning & Batch Norm
@article{ruder2016overview,
  title={An overview of gradient descent optimization algorithms},
  author={Ruder, Sebastian},
  journal={arXiv preprint arXiv:1609.04747},
  year={2016}
}

%ML Book
@book{Witten2011,
  author        = "I.H.Witten, E.Frank and M.A.Hall",
  title         	= "DATA MINING. Practical Machine Learning Tools and Techniques",
  edition 	= 3,
  publisher   	= "Morgan Kaufman",
  year        	= "2011",
}

%ADAM
@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

%ML Book
@book{Theodoridis2009,
  author        = "S.Theodoridis and K.Koutroumbas",
  title         	= "Pattern Recognition",
  edition	= 4,
  publisher   	= "Academic Press",
  year        	= "2009",
}

%Curriculum Learning
@article{Bengio2009,
  author        = "Y.Bengio, J.Louradour, R.Collobert and J.Weston",
  title         = "Curriculum Learning",
  journal       = "Procedures of the International Conference on Machine Learning",
  volume        = 26,
  pages         = "41-48",
  year          = 2009,
}
%V. Early Curric learning!
@article{ELMAN199371,
title = "Learning and development in neural networks: the importance of starting small",
journal = "Cognition",
volume = "48",
number = "1",
pages = "71 - 99",
year = "1993",
issn = "0010-0277",
doi = "https://doi.org/10.1016/0010-0277(93)90058-4",
url = "http://www.sciencedirect.com/science/article/pii/0010027793900584",
author = "Jeffrey L. Elman"
}

%?
@article{Bubeck2012,
  author        = "S.Bubeck, N.Cesa-Bianchi",
  title         	= "Regret Analysis of stochastic and nonstochastic multi-armed bandit problems",
  journal       = "Machine Learning",
  volume        = 5,
  pages         = "1-122",
  year          = 2012,
}

%Active Bias
@article{Chang18,
  author        = "H-S Chang, E.Learned-Miller, A.McCallum",
  title         	= "Active Bias: Training More Accuracy Neural Networks by Emphasizing High Variance Samples",
  journal       = "Advances in Neural Information Processing Systems",
  volume        = 31,
  pages         = "1-122",
  year          = 2017,
}

%Conv Nets
@inproceedings{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={1097--1105},
  year={2012}
}

%Self Paced Learning
@inproceedings{kumar2010self,
  title={Self-paced learning for latent variable models},
  author={Kumar, M Pawan and Packer, Benjamin and Koller, Daphne},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1189--1197},
  year={2010}
}
%SPL with diversity
@inproceedings{jiang2014self,
  title={Self-paced learning with diversity},
  author={Jiang, Lu and Meng, Deyu and Yu, Shoou-I and Lan, Zhenzhong and Shan, Shiguang and Hauptmann, Alexander},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2078--2086},
  year={2014}
}

%SPL for Conv Nets
@misc{avramova2015curriculum,
  title={Curriculum learning with deep convolutional neural networks},
  author={Avramova, Vanya},
  year={2015}
}
%Handwritten Curriculum Learning
@inproceedings{louradour2014curriculum,
  title={Curriculum learning for handwritten text line recognition},
  author={Louradour, J{\'e}r{\^o}me and Kermorvant, Christopher},
  booktitle={Document Analysis Systems (DAS), 2014 11th IAPR International Workshop on},
  pages={56--60},
  year={2014},
  organization={IEEE}
}

%Curriculum Learning example
@inproceedings{pentina2015curriculum,
  title={Curriculum learning of multiple tasks},
  author={Pentina, Anastasia and Sharmanska, Viktoriia and Lampert, Christoph H},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={5492--5500},
  year={2015}
}

%Self-Paced Curriculum Learning
@inproceedings{jiang2015self,
  title={Self-Paced Curriculum Learning.},
  author={Jiang, Lu and Meng, Deyu and Zhao, Qian and Shan, Shiguang and Hauptmann, Alexander G},
  booktitle={AAAI},
  volume={2},
  number={5.4},
  pages={6},
  year={2015}
}

%SSVM
@inproceedings{felzenszwalb2008discriminatively,
  title={A discriminatively trained, multiscale, deformable part model},
  author={Felzenszwalb, Pedro and McAllester, David and Ramanan, Deva},
  booktitle={Computer Vision and Pattern Recognition, 2008. CVPR 2008. IEEE Conference on},
  pages={1--8},
  year={2008},
  organization={IEEE}
}


%Backprop
@inproceedings{lecun1988theoretical,
  title={A theoretical framework for back-propagation},
  author={LeCun, Yann and Touresky, D and Hinton, G and Sejnowski, T},
  booktitle={Proceedings of the 1988 connectionist models summer school},
  volume={1},
  pages={21--28},
  year={1988},
  organization={CMU, Pittsburgh, Pa: Morgan Kaufmann}
}

%BALD
@inproceedings{gal2016dropout,
  title={Dropout as a Bayesian approximation: Representing model uncertainty in deep learning},
  author={Gal, Yarin and Ghahramani, Zoubin},
  booktitle={international conference on machine learning},
  pages={1050--1059},
  year={2016}
}

@article{gal2016uncertainty,
  title={Uncertainty in deep learning},
  author={Gal, Yarin},
  journal={University of Cambridge},
  year={2016}
}

@article{gal2015dropout,
  title={Dropout as a Bayesian approximation},
  author={Gal, Yarin and Ghahramani, Zoubin},
  journal={arXiv preprint arXiv:1506.02157},
  year={2015}
}

@article{gal2017deep,
  title={Deep bayesian active learning with image data},
  author={Gal, Yarin and Islam, Riashat and Ghahramani, Zoubin},
  journal={arXiv preprint arXiv:1703.02910},
  year={2017}
}
%Never Ending Learning
@article{mitchell2018never,
  title={Never-ending learning},
  author={Mitchell, Tom and Cohen, William and Hruschka, Estevam and Talukdar, Partha and Yang, Bo and Betteridge, Justin and Carlson, Andrew and Dalvi, B and Gardner, Matt and Kisiel, Bryan and others},
  journal={Communications of the ACM},
  volume={61},
  number={5},
  pages={103--115},
  year={2018},
  publisher={ACM}
}

%DeepMind Automated Curricula
@article{graves2017automated,
  title={Automated curriculum learning for neural networks},
  author={Graves, Alex and Bellemare, Marc G and Menick, Jacob and Munos, Remi and Kavukcuoglu, Koray},
  journal={arXiv preprint arXiv:1704.03003},
  year={2017}
}

%Active Learning

%Curriculum Learning (or similar)
%''Training connectionist networks with queries and selective sampling''
%LEARNING TO EXECUTE -Wojciech Zaremba∗

%ADAM
%Adam: a Method for Stochastic Optimization

%Batch Normalization
%Sergey Ioffe and Christian Szegedy. Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift

%Gradient Descent
%	RUMELHART, D. E., HINTON, G. E., and WILLIAMS, R. J. (1986): Learning internal representations by error propagation. In Parallel distributed processing: Explorations in the microstructure of cognition, vol.I, 318-362, Bradford Books.

%SGD
%Large-scale machine learning with stochastic gradient descent, L Bottou - Proceedings of COMPSTAT'2010, 2010 - Springer
%Generalization Error
%Inference for the Generalization Error
